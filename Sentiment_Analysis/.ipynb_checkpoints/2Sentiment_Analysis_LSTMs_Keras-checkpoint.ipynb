{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/DATA\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ac57exoS09qI"
   },
   "source": [
    "# Loading and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jReOosMry_OD"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Emotions.txt' ,sep=';', names=['text', 'category'], index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "AGYvrD6pz6yF",
    "outputId": "1d75dec6-cf9c-44b0-833c-1180c7c5772a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text category\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc21pD860Ekg",
    "outputId": "4f61b8b0-4a74-4dbf-b2d6-71f36355f0e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         5362\n",
       "sadness     4666\n",
       "anger       2159\n",
       "fear        1937\n",
       "love        1304\n",
       "surprise     572\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOjrBjbT0FUF",
    "outputId": "567e4e7f-7b50-4c03-c24b-bb8460a154fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sadness' 'anger' 'love' 'surprise' 'fear' 'joy']\n"
     ]
    }
   ],
   "source": [
    "possible_labels = df.category.unique()\n",
    "print(possible_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r0u6TEQy0FWm",
    "outputId": "ef3ded33-ad2a-4d33-9b63-fdc0dc1ee925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sadness': 0, 'anger': 1, 'love': 2, 'surprise': 3, 'fear': 4, 'joy': 5}\n"
     ]
    }
   ],
   "source": [
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "2LA0LDtv0FZF",
    "outputId": "c2444df5-68e3-4f1f-8c20-865b001c5dcf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>i feel like throwing away the shitty piece of ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>im starting to feel wryly amused at the banal ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>i find every body beautiful and only want peop...</td>\n",
       "      <td>joy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>i hear are owners who feel victimized by their...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>i say goodbye to the fam theyre all sad a cryi...</td>\n",
       "      <td>anger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text category  label\n",
       "0                             i didnt feel humiliated  sadness      0\n",
       "1   i can go from feeling so hopeless to so damned...  sadness      0\n",
       "2    im grabbing a minute to post i feel greedy wrong    anger      1\n",
       "3   i am ever feeling nostalgic about the fireplac...     love      2\n",
       "4                                i am feeling grouchy    anger      1\n",
       "..                                                ...      ...    ...\n",
       "95  i feel like throwing away the shitty piece of ...  sadness      0\n",
       "96  im starting to feel wryly amused at the banal ...      joy      5\n",
       "97  i find every body beautiful and only want peop...      joy      5\n",
       "98  i hear are owners who feel victimized by their...  sadness      0\n",
       "99  i say goodbye to the fam theyre all sad a cryi...    anger      1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.category.replace(label_dict)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8FlKXgCc0FbW"
   },
   "outputs": [],
   "source": [
    "df = df.drop(['category'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "qmYMAsmqT1ay",
    "outputId": "028149aa-c619-4530-d409-c8497cd4dbf7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ive been feeling a little burdened lately wasn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ive been taking or milligrams or times recomme...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i feel as confused about life as a teenager or...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i have been with petronas for years i feel tha...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i feel romantic too</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i feel like i have to make the suffering i m s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i do feel that running is a divine experience ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i think it s the easiest time of year to feel ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>i feel low energy i m just thirsty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>i have immense sympathy with the general point...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>i do not feel reassured anxiety is on each side</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>i didnt really feel that embarrassed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>i feel pretty pathetic most of the time</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>i started feeling sentimental about dolls i ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>i now feel compromised and skeptical of the va...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "0                             i didnt feel humiliated      0\n",
       "1   i can go from feeling so hopeless to so damned...      0\n",
       "2    im grabbing a minute to post i feel greedy wrong      1\n",
       "3   i am ever feeling nostalgic about the fireplac...      2\n",
       "4                                i am feeling grouchy      1\n",
       "5   ive been feeling a little burdened lately wasn...      0\n",
       "6   ive been taking or milligrams or times recomme...      3\n",
       "7   i feel as confused about life as a teenager or...      4\n",
       "8   i have been with petronas for years i feel tha...      5\n",
       "9                                 i feel romantic too      2\n",
       "10  i feel like i have to make the suffering i m s...      0\n",
       "11  i do feel that running is a divine experience ...      5\n",
       "12  i think it s the easiest time of year to feel ...      1\n",
       "13                 i feel low energy i m just thirsty      0\n",
       "14  i have immense sympathy with the general point...      5\n",
       "15    i do not feel reassured anxiety is on each side      5\n",
       "16               i didnt really feel that embarrassed      0\n",
       "17            i feel pretty pathetic most of the time      0\n",
       "18  i started feeling sentimental about dolls i ha...      0\n",
       "19  i now feel compromised and skeptical of the va...      4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ye4iFOiLtWSF"
   },
   "source": [
    "# Training/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5-u8yk61tcpI"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NnDQm1Autl76"
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(df['text'], \n",
    "                                                  df['label'], \n",
    "                                                  test_size=0.20, \n",
    "                                                  random_state=17, \n",
    "                                                  stratify = df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ATimb5gz0OZ6"
   },
   "outputs": [],
   "source": [
    "x_train=x_train.to_numpy()\n",
    "x_val=x_val.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "y_val=y_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ioSCPiiQT6nc",
    "outputId": "4e7a669a-036d-42db-b489-f3a7cc5da0a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i feel sarcastic more often than not'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWyf22Hqc3b6",
    "outputId": "692be252-9600-465f-be4c-54ee869f88b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12800,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nl_djslvELqS",
    "outputId": "68350a26-0055-4622-8552-3037ea4243a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 5 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wq58tX-lrtG"
   },
   "source": [
    "# Text Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ooFR8I-hl-z6",
    "outputId": "b1e1ef39-a64b-49c3-8d8e-947f617fa6ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hemant./nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/hemant./nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "y3SL4Smtl-9J"
   },
   "outputs": [],
   "source": [
    "stopwords_english = stopwords.words('english')\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PQCBLYmLl-_4"
   },
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    '''\n",
    "    Input: \n",
    "        text: a string containing a text\n",
    "    Output:\n",
    "        text_clean: a list of words containing the processed text\n",
    "    \n",
    "    '''\n",
    "    # remove number \n",
    "    text = re.sub('[0-9]', '', text)\n",
    "    # remove stock market tickers like $GE\n",
    "    text = re.sub(r'\\$\\w*', '', text)\n",
    "    # remove old style text \"RT\"\n",
    "    text = re.sub(r'^RT[\\s]+', '', text)\n",
    "    # remove hyperlinks\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    text = re.sub(r'#', '', text)\n",
    "    # remove the dates like Mar 30 2013\n",
    "    text = re.sub('(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s\\d{2}\\s\\d{4}', ' ', text)\n",
    "    text = re.sub(r'//', '', text)\n",
    "    # tokenize texts\n",
    "    text_tokens = word_tokenize(text)\n",
    "    \n",
    "    text_clean = []\n",
    "    \n",
    "    for word in text_tokens:\n",
    "       if (word not in stopwords_english and # remove stopwords\n",
    "            word not in string.punctuation): # remove punctuation\n",
    "            text_clean.append(word)\n",
    "            #stem_word = stemmer.stem(word) # stemming word\n",
    "            #text_clean.append(stem_word)\n",
    "    \n",
    "    return  text_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UX7lBAV9pgEC"
   },
   "source": [
    "# LSTMs in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tr4AvRhSVoOk",
    "outputId": "b5206a9d-4d38-4bcf-d7b0-a9ec9550cf3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting scipy>=0.14\n",
      "  Using cached scipy-1.7.1.tar.gz (36.1 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Users/hemant./miniforge3/bin/python3.9 /Users/hemant./miniforge3/lib/python3.9/site-packages/pip/_vendor/pep517/in_process/_in_process.py prepare_metadata_for_build_wheel /var/folders/1_/5jmrsdkn5zjfcj8_nmbnx2t80000gn/T/tmp__zyailg\n",
      "         cwd: /private/var/folders/1_/5jmrsdkn5zjfcj8_nmbnx2t80000gn/T/pip-install-_e40ps5k/scipy_73ae5b76b2a9489ea8eb6be348e00978\n",
      "    Complete output (183 lines):\n",
      "    setup.py:490: UserWarning: Unrecognized setuptools command ('dist_info --egg-base /private/var/folders/1_/5jmrsdkn5zjfcj8_nmbnx2t80000gn/T/pip-modern-metadata-m4uqyxa7'), proceeding with generating Cython sources and expanding templates\n",
      "      warnings.warn(\"Unrecognized setuptools command ('{}'), proceeding with \"\n",
      "    Running from SciPy source directory.\n",
      "    Running scipy/linalg/_generate_pyx.py\n",
      "    Running scipy/special/_generate_pyx.py\n",
      "    Running scipy/stats/_generate_pyx.py\n",
      "    Processing scipy/cluster/_vq.pyx\n",
      "    Processing scipy/cluster/_optimal_leaf_ordering.pyx\n",
      "    Processing scipy/cluster/_hierarchy.pyx\n",
      "    Processing scipy/ndimage/src/_cytest.pyx\n",
      "    Processing scipy/ndimage/src/_ni_label.pyx\n",
      "    Processing scipy/linalg/cython_lapack.pyx\n",
      "    Processing scipy/linalg/_matfuncs_sqrtm_triu.pyx\n",
      "    Processing scipy/linalg/_solve_toeplitz.pyx\n",
      "    Processing scipy/linalg/cython_blas.pyx\n",
      "    Processing scipy/linalg/_decomp_update.pyx.in\n",
      "    Processing scipy/optimize/_group_columns.pyx\n",
      "    Processing scipy/optimize/_bglu_dense.pyx\n",
      "    Processing scipy/optimize/_trlib/_trlib.pyx\n",
      "    Processing scipy/optimize/_highs/cython/src/_highs_constants.pyx\n",
      "    Processing scipy/optimize/_highs/cython/src/_highs_wrapper.pyx\n",
      "    Processing scipy/optimize/_lsq/givens_elimination.pyx\n",
      "    Processing scipy/optimize/cython_optimize/_zeros.pyx.in\n",
      "    Processing scipy/io/matlab/mio_utils.pyx\n",
      "    Processing scipy/io/matlab/streams.pyx\n",
      "    Processing scipy/io/matlab/mio5_utils.pyx\n",
      "    Processing scipy/_lib/_ccallback_c.pyx\n",
      "    Processing scipy/_lib/_test_deprecation_def.pyx\n",
      "    Processing scipy/_lib/_test_deprecation_call.pyx\n",
      "    Processing scipy/_lib/messagestream.pyx\n",
      "    Processing scipy/special/_ufuncs_cxx.pyx\n",
      "    Processing scipy/special/cython_special.pyx\n",
      "    Processing scipy/special/_ellip_harm_2.pyx\n",
      "    Processing scipy/special/_comb.pyx\n",
      "    Processing scipy/special/_test_round.pyx\n",
      "    Processing scipy/special/_ufuncs.pyx\n",
      "    Processing scipy/fftpack/convolve.pyx\n",
      "    Processing scipy/interpolate/interpnd.pyx\n",
      "    Processing scipy/interpolate/_bspl.pyx\n",
      "    Processing scipy/interpolate/_ppoly.pyx\n",
      "    Processing scipy/sparse/_csparsetools.pyx.in\n",
      "    Processing scipy/sparse/csgraph/_shortest_path.pyx\n",
      "    Processing scipy/sparse/csgraph/_traversal.pyx\n",
      "    Processing scipy/sparse/csgraph/_flow.pyx\n",
      "    warning: _cython_special_custom.pxi:9:8: Unreachable code\n",
      "    warning: _cython_special_custom.pxi:13:4: Unreachable code\n",
      "    warning: _cython_special_custom.pxi:21:8: Unreachable code\n",
      "    warning: _cython_special_custom.pxi:25:4: Unreachable code\n",
      "    warning: _cython_special_custom.pxi:33:8: Unreachable code\n",
      "    warning: _cython_special_custom.pxi:37:4: Unreachable code\n",
      "    warning: _cython_special_custom.pxi:45:8: Unreachable code\n",
      "    warning: _cython_special_custom.pxi:49:4: Unreachable code\n",
      "    Processing scipy/sparse/csgraph/_tools.pyx\n",
      "    Processing scipy/sparse/csgraph/_matching.pyx\n",
      "    Processing scipy/sparse/csgraph/_reordering.pyx\n",
      "    Processing scipy/sparse/csgraph/_min_spanning_tree.pyx\n",
      "    Processing scipy/spatial/ckdtree.pyx\n",
      "    Processing scipy/spatial/_voronoi.pyx\n",
      "    Processing scipy/spatial/_hausdorff.pyx\n",
      "    Processing scipy/spatial/qhull.pyx\n",
      "    Processing scipy/spatial/transform/rotation.pyx\n",
      "    Processing scipy/signal/_max_len_seq_inner.pyx\n",
      "    Processing scipy/signal/_peak_finding_utils.pyx\n",
      "    Processing scipy/signal/_upfirdn_apply.pyx\n",
      "    Processing scipy/signal/_spectral.pyx\n",
      "    Processing scipy/signal/_sosfilt.pyx\n",
      "    Processing scipy/stats/_stats.pyx\n",
      "    Processing scipy/stats/_qmc_cy.pyx\n",
      "    Processing scipy/stats/_sobol.pyx\n",
      "    Processing scipy/stats/biasedurn.pyx\n",
      "    Processing scipy/stats/_boost/src/beta_ufunc.pyx\n",
      "    Processing scipy/stats/_boost/src/nbinom_ufunc.pyx\n",
      "    Processing scipy/stats/_boost/src/binom_ufunc.pyx\n",
      "    Cythonizing sources\n",
      "    lapack_opt_info:\n",
      "    lapack_mkl_info:\n",
      "    customize UnixCCompiler\n",
      "      libraries mkl_rt not found in ['/Users/hemant./miniforge3/lib', '/usr/local/lib', '/usr/lib']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    openblas_lapack_info:\n",
      "      libraries openblas not found in ['/Users/hemant./miniforge3/lib', '/usr/local/lib', '/usr/lib']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    openblas_clapack_info:\n",
      "      libraries openblas,lapack not found in ['/Users/hemant./miniforge3/lib', '/usr/local/lib', '/usr/lib']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    flame_info:\n",
      "      libraries flame not found in ['/Users/hemant./miniforge3/lib', '/usr/local/lib', '/usr/lib']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_3_10_threads_info:\n",
      "    Setting PTATLAS=ATLAS\n",
      "      libraries lapack_atlas not found in /Users/hemant./miniforge3/lib\n",
      "      libraries tatlas,tatlas not found in /Users/hemant./miniforge3/lib\n",
      "      libraries lapack_atlas not found in /usr/local/lib\n",
      "      libraries tatlas,tatlas not found in /usr/local/lib\n",
      "      libraries lapack_atlas not found in /usr/lib\n",
      "      libraries tatlas,tatlas not found in /usr/lib\n",
      "    <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_3_10_info:\n",
      "      libraries lapack_atlas not found in /Users/hemant./miniforge3/lib\n",
      "      libraries satlas,satlas not found in /Users/hemant./miniforge3/lib\n",
      "      libraries lapack_atlas not found in /usr/local/lib\n",
      "      libraries satlas,satlas not found in /usr/local/lib\n",
      "      libraries lapack_atlas not found in /usr/lib\n",
      "      libraries satlas,satlas not found in /usr/lib\n",
      "    <class 'numpy.distutils.system_info.atlas_3_10_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_threads_info:\n",
      "    Setting PTATLAS=ATLAS\n",
      "      libraries lapack_atlas not found in /Users/hemant./miniforge3/lib\n",
      "      libraries ptf77blas,ptcblas,atlas not found in /Users/hemant./miniforge3/lib\n",
      "      libraries lapack_atlas not found in /usr/local/lib\n",
      "      libraries ptf77blas,ptcblas,atlas not found in /usr/local/lib\n",
      "      libraries lapack_atlas not found in /usr/lib\n",
      "      libraries ptf77blas,ptcblas,atlas not found in /usr/lib\n",
      "    <class 'numpy.distutils.system_info.atlas_threads_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_info:\n",
      "      libraries lapack_atlas not found in /Users/hemant./miniforge3/lib\n",
      "      libraries f77blas,cblas,atlas not found in /Users/hemant./miniforge3/lib\n",
      "      libraries lapack_atlas not found in /usr/local/lib\n",
      "      libraries f77blas,cblas,atlas not found in /usr/local/lib\n",
      "      libraries lapack_atlas not found in /usr/lib\n",
      "      libraries f77blas,cblas,atlas not found in /usr/lib\n",
      "    <class 'numpy.distutils.system_info.atlas_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    accelerate_info:\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    lapack_info:\n",
      "      libraries lapack not found in ['/Users/hemant./miniforge3/lib', '/usr/local/lib', '/usr/lib']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    /private/var/folders/1_/5jmrsdkn5zjfcj8_nmbnx2t80000gn/T/pip-build-env-dx0ui8_p/overlay/lib/python3.9/site-packages/numpy/distutils/system_info.py:1748: UserWarning:\n",
      "        Lapack (http://www.netlib.org/lapack/) libraries not found.\n",
      "        Directories to search for the libraries can be specified in the\n",
      "        numpy/distutils/site.cfg file (section [lapack]) or by setting\n",
      "        the LAPACK environment variable.\n",
      "      return getattr(self, '_calc_info_{}'.format(name))()\n",
      "    lapack_src_info:\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    /private/var/folders/1_/5jmrsdkn5zjfcj8_nmbnx2t80000gn/T/pip-build-env-dx0ui8_p/overlay/lib/python3.9/site-packages/numpy/distutils/system_info.py:1748: UserWarning:\n",
      "        Lapack (http://www.netlib.org/lapack/) sources not found.\n",
      "        Directories to search for the sources can be specified in the\n",
      "        numpy/distutils/site.cfg file (section [lapack_src]) or by setting\n",
      "        the LAPACK_SRC environment variable.\n",
      "      return getattr(self, '_calc_info_{}'.format(name))()\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    Traceback (most recent call last):\n",
      "      File \"/Users/hemant./miniforge3/lib/python3.9/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 280, in <module>\n",
      "        main()\n",
      "      File \"/Users/hemant./miniforge3/lib/python3.9/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 263, in main\n",
      "        json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "      File \"/Users/hemant./miniforge3/lib/python3.9/site-packages/pip/_vendor/pep517/in_process/_in_process.py\", line 133, in prepare_metadata_for_build_wheel\n",
      "        return hook(metadata_directory, config_settings)\n",
      "      File \"/private/var/folders/1_/5jmrsdkn5zjfcj8_nmbnx2t80000gn/T/pip-build-env-dx0ui8_p/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 166, in prepare_metadata_for_build_wheel\n",
      "        self.run_setup()\n",
      "      File \"/private/var/folders/1_/5jmrsdkn5zjfcj8_nmbnx2t80000gn/T/pip-build-env-dx0ui8_p/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 258, in run_setup\n",
      "        super(_BuildMetaLegacyBackend,\n",
      "      File \"/private/var/folders/1_/5jmrsdkn5zjfcj8_nmbnx2t80000gn/T/pip-build-env-dx0ui8_p/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 150, in run_setup\n",
      "        exec(compile(code, __file__, 'exec'), locals())\n",
      "      File \"setup.py\", line 629, in <module>\n",
      "        setup_package()\n",
      "      File \"setup.py\", line 625, in setup_package\n",
      "        setup(**metadata)\n",
      "      File \"/private/var/folders/1_/5jmrsdkn5zjfcj8_nmbnx2t80000gn/T/pip-build-env-dx0ui8_p/overlay/lib/python3.9/site-packages/numpy/distutils/core.py\", line 135, in setup\n",
      "        config = configuration()\n",
      "      File \"setup.py\", line 528, in configuration\n",
      "        raise NotFoundError(msg)\n",
      "    numpy.distutils.system_info.NotFoundError: No BLAS/LAPACK libraries found. Note: Accelerate is no longer supported.\n",
      "    To build Scipy from sources, BLAS & LAPACK libraries need to be installed.\n",
      "    See site.cfg.example in the Scipy source directory and\n",
      "    https://docs.scipy.org/doc/scipy/reference/building/index.html for details.\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/47/33/a24aec22b7be7fdb10ec117a95e1e4099890d8bbc6646902f443fc7719d1/scipy-1.7.1.tar.gz#sha256=6b47d5fa7ea651054362561a28b1ccc8da9368a39514c1bbf6c0977a1c376764 (from https://pypi.org/simple/scipy/) (requires-python:>=3.7,<3.10). Command errored out with exit status 1: /Users/hemant./miniforge3/bin/python3.9 /Users/hemant./miniforge3/lib/python3.9/site-packages/pip/_vendor/pep517/in_process/_in_process.py prepare_metadata_for_build_wheel /var/folders/1_/5jmrsdkn5zjfcj8_nmbnx2t80000gn/T/tmp__zyailg Check the logs for full command output.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Using cached scipy-1.7.0.tar.gz (36.1 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25l|"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nx_2G4ITq-0m"
   },
   "outputs": [],
   "source": [
    "## upload word emebedding file on google drive\n",
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words, words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJ8yXwa4q-3w"
   },
   "outputs": [],
   "source": [
    "words, word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlK3974YVoRU"
   },
   "outputs": [],
   "source": [
    "def text_to_indices(X, word_to_index, max_len):\n",
    "    m = X.shape[0]                                   \n",
    "    \n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    \n",
    "    for i in range(m):\n",
    "      processed_text = process_text(X[i])\n",
    "      j = 0\n",
    "      for w in processed_text:\n",
    "        if (w in words) & (j < max_len):\n",
    "          X_indices[i, j] = word_to_index[w]\n",
    "        j += 1 \n",
    "\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAoTPzEvwId5"
   },
   "outputs": [],
   "source": [
    "x_train_indices = text_to_indices(x_train, word_to_index, max_len = 20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TkgLKr9qwIhC",
    "outputId": "e0cbdb87-9aca-43d5-9519-3fe22cddca76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12800, 20)"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZRtFwOsawIoN",
    "outputId": "aa9f850c-a717-4ca4-90d3-6c7f425739b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([385595., 219372.,  90668.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "            0.,      0.,      0.,      0.,      0.,      0.])"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_indices[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R98azIBH-RUp"
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qi9bASBl-RXg"
   },
   "outputs": [],
   "source": [
    "y_train_oh = convert_to_one_hot(y_train, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTVZD0u9wIxL"
   },
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "   \n",
    "    vocab_len = len(word_to_index)+1                 \n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      \n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable = False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_p2xOPf2T6b"
   },
   "outputs": [],
   "source": [
    "def lstm_model(input_shape, word_to_vec_map, word_to_index):\n",
    "\n",
    "    text_to_indices = Input(input_shape, dtype = 'int32')\n",
    "\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    embeddings = embedding_layer(text_to_indices)   \n",
    "    \n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    \n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    \n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    X = Dense(6)(X)\n",
    "    \n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    model = Model(inputs = text_to_indices, outputs = X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3ZEJS9J2T9f",
    "outputId": "cfbc2f7a-f33b-4c62-f3e2-11bbc57fdfb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 20, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 20, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 774       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 20,224,056\n",
      "Trainable params: 224,006\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_len= 20\n",
    "model = lstm_model((max_len,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UElXKBmaaMlT"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSYpWujJcGNv",
    "outputId": "23d0d824-25b9-4515-d6d8-623256b9c67c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "400/400 [==============================] - 22s 47ms/step - loss: 1.4580 - accuracy: 0.4329\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 1.1236 - accuracy: 0.5799\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 19s 46ms/step - loss: 0.8918 - accuracy: 0.6747\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 0.6984 - accuracy: 0.7494\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 19s 46ms/step - loss: 0.5431 - accuracy: 0.8070\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 0.4541 - accuracy: 0.8375\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 19s 46ms/step - loss: 0.3578 - accuracy: 0.8741\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 0.3236 - accuracy: 0.8798\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 19s 46ms/step - loss: 0.2742 - accuracy: 0.8974\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 0.2402 - accuracy: 0.9090\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 0.2106 - accuracy: 0.9190\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 19s 46ms/step - loss: 0.1827 - accuracy: 0.9282\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 0.1675 - accuracy: 0.9359\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 0.1577 - accuracy: 0.9374\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 0.1378 - accuracy: 0.9448\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 19s 46ms/step - loss: 0.1223 - accuracy: 0.9538\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 0.1277 - accuracy: 0.9482\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 0.1083 - accuracy: 0.9585\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 0.1234 - accuracy: 0.9526\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 19s 46ms/step - loss: 0.0943 - accuracy: 0.9649\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 0.0721 - accuracy: 0.9714\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 0.0822 - accuracy: 0.9699\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 0.0778 - accuracy: 0.9695\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 0.0868 - accuracy: 0.9653\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 0.0680 - accuracy: 0.9755\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 0.0650 - accuracy: 0.9766\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0665 - accuracy: 0.9738\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 18s 44ms/step - loss: 0.0569 - accuracy: 0.9772\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0567 - accuracy: 0.9802\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 18s 44ms/step - loss: 0.0572 - accuracy: 0.9800\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 18s 44ms/step - loss: 0.0501 - accuracy: 0.9800\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0460 - accuracy: 0.9813\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0437 - accuracy: 0.9843\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0550 - accuracy: 0.9789\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0502 - accuracy: 0.9855\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0365 - accuracy: 0.9874\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0450 - accuracy: 0.9850\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0552 - accuracy: 0.9813\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0375 - accuracy: 0.9888\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0424 - accuracy: 0.9862\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0425 - accuracy: 0.9854\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 19s 46ms/step - loss: 0.0271 - accuracy: 0.9894\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0334 - accuracy: 0.9882\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 0.0401 - accuracy: 0.9868\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0299 - accuracy: 0.9908\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0309 - accuracy: 0.9899\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 18s 44ms/step - loss: 0.0309 - accuracy: 0.9880\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 18s 44ms/step - loss: 0.0283 - accuracy: 0.9896\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 0.0270 - accuracy: 0.9892\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 18s 46ms/step - loss: 0.0227 - accuracy: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f562f7ec610>"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_indices, y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWFT081GpySJ",
    "outputId": "111f92cb-455b-4ea2-9ca0-5010de051fc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 2s 16ms/step - loss: 0.8961 - accuracy: 0.8566\n",
      "validation accuracy =  0.8565624952316284\n"
     ]
    }
   ],
   "source": [
    "X_val_indices = text_to_indices(x_val, word_to_index, max_len = 20)\n",
    "Y_val_oh = convert_to_one_hot(y_val, C = 6)\n",
    "loss, acc = model.evaluate(X_val_indices, Y_val_oh)\n",
    "\n",
    "print(\"validation accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wy8JMWIzoYtd"
   },
   "source": [
    "# Test your own sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqaOKgwApyVd",
    "outputId": "0a016e72-ae1f-4e94-bece-4edb95f695d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted emotion is: fear\n"
     ]
    }
   ],
   "source": [
    "## Predict emotion \n",
    "input_string = np.array(['i am getting butterflies in my stomach'])\n",
    "X = text_to_indices(input_string, word_to_index, max_len = 20)\n",
    "prediction = np.argmax(model.predict(X))\n",
    "labels = {'sadness': 0, 'anger': 1, 'love': 2, 'surprise': 3, 'fear': 4, 'joy': 5}\n",
    "for key, value in labels.items():\n",
    "  if prediction == value:\n",
    "    print(\"predicted emotion is: \" + str(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaFh__vdtONx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lcyr1Ru_tOQc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment_Analysis_LSTMs_Keras.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow_2)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
