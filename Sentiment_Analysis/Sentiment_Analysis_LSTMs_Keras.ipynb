{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_LSTMs_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxepDBL-z7Xu"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac57exoS09qI"
      },
      "source": [
        "# Loading and Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LBX3jnYF6YY",
        "outputId": "8513ec96-7f6b-480c-c42d-67c1f0c94db8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/DATA\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Emotions.txt  glove.6B.200d.txt  glove.6B.50d.txt  theta.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jReOosMry_OD"
      },
      "source": [
        "df = pd.read_csv('Emotions.txt' ,sep=';', names=['text', 'category'], index_col=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "AGYvrD6pz6yF",
        "outputId": "1d75dec6-cf9c-44b0-833c-1180c7c5772a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text category\n",
              "0                            i didnt feel humiliated  sadness\n",
              "1  i can go from feeling so hopeless to so damned...  sadness\n",
              "2   im grabbing a minute to post i feel greedy wrong    anger\n",
              "3  i am ever feeling nostalgic about the fireplac...     love\n",
              "4                               i am feeling grouchy    anger"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc21pD860Ekg",
        "outputId": "4f61b8b0-4a74-4dbf-b2d6-71f36355f0e8"
      },
      "source": [
        "df.category.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "joy         5362\n",
              "sadness     4666\n",
              "anger       2159\n",
              "fear        1937\n",
              "love        1304\n",
              "surprise     572\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOjrBjbT0FUF",
        "outputId": "567e4e7f-7b50-4c03-c24b-bb8460a154fa"
      },
      "source": [
        "possible_labels = df.category.unique()\n",
        "print(possible_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sadness' 'anger' 'love' 'surprise' 'fear' 'joy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0u6TEQy0FWm",
        "outputId": "ef3ded33-ad2a-4d33-9b63-fdc0dc1ee925"
      },
      "source": [
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "\n",
        "print(label_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'sadness': 0, 'anger': 1, 'love': 2, 'surprise': 3, 'fear': 4, 'joy': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "2LA0LDtv0FZF",
        "outputId": "c2444df5-68e3-4f1f-8c20-865b001c5dcf"
      },
      "source": [
        "df['label'] = df.category.replace(label_dict)\n",
        "df.head(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>i feel like throwing away the shitty piece of ...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>im starting to feel wryly amused at the banal ...</td>\n",
              "      <td>joy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>i find every body beautiful and only want peop...</td>\n",
              "      <td>joy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>i hear are owners who feel victimized by their...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>i say goodbye to the fam theyre all sad a cryi...</td>\n",
              "      <td>anger</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text category  label\n",
              "0                             i didnt feel humiliated  sadness      0\n",
              "1   i can go from feeling so hopeless to so damned...  sadness      0\n",
              "2    im grabbing a minute to post i feel greedy wrong    anger      1\n",
              "3   i am ever feeling nostalgic about the fireplac...     love      2\n",
              "4                                i am feeling grouchy    anger      1\n",
              "..                                                ...      ...    ...\n",
              "95  i feel like throwing away the shitty piece of ...  sadness      0\n",
              "96  im starting to feel wryly amused at the banal ...      joy      5\n",
              "97  i find every body beautiful and only want peop...      joy      5\n",
              "98  i hear are owners who feel victimized by their...  sadness      0\n",
              "99  i say goodbye to the fam theyre all sad a cryi...    anger      1\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FlKXgCc0FbW"
      },
      "source": [
        "df = df.drop(['category'], axis = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "qmYMAsmqT1ay",
        "outputId": "028149aa-c619-4530-d409-c8497cd4dbf7"
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ive been feeling a little burdened lately wasn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ive been taking or milligrams or times recomme...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>i feel as confused about life as a teenager or...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>i have been with petronas for years i feel tha...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>i feel romantic too</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>i feel like i have to make the suffering i m s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>i do feel that running is a divine experience ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>i think it s the easiest time of year to feel ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>i feel low energy i m just thirsty</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>i have immense sympathy with the general point...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>i do not feel reassured anxiety is on each side</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>i didnt really feel that embarrassed</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>i feel pretty pathetic most of the time</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>i started feeling sentimental about dolls i ha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>i now feel compromised and skeptical of the va...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text  label\n",
              "0                             i didnt feel humiliated      0\n",
              "1   i can go from feeling so hopeless to so damned...      0\n",
              "2    im grabbing a minute to post i feel greedy wrong      1\n",
              "3   i am ever feeling nostalgic about the fireplac...      2\n",
              "4                                i am feeling grouchy      1\n",
              "5   ive been feeling a little burdened lately wasn...      0\n",
              "6   ive been taking or milligrams or times recomme...      3\n",
              "7   i feel as confused about life as a teenager or...      4\n",
              "8   i have been with petronas for years i feel tha...      5\n",
              "9                                 i feel romantic too      2\n",
              "10  i feel like i have to make the suffering i m s...      0\n",
              "11  i do feel that running is a divine experience ...      5\n",
              "12  i think it s the easiest time of year to feel ...      1\n",
              "13                 i feel low energy i m just thirsty      0\n",
              "14  i have immense sympathy with the general point...      5\n",
              "15    i do not feel reassured anxiety is on each side      5\n",
              "16               i didnt really feel that embarrassed      0\n",
              "17            i feel pretty pathetic most of the time      0\n",
              "18  i started feeling sentimental about dolls i ha...      0\n",
              "19  i now feel compromised and skeptical of the va...      4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye4iFOiLtWSF"
      },
      "source": [
        "# Training/Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-u8yk61tcpI"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnDQm1Autl76"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(df['text'], \n",
        "                                                  df['label'], \n",
        "                                                  test_size=0.20, \n",
        "                                                  random_state=17, \n",
        "                                                  stratify = df['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATimb5gz0OZ6"
      },
      "source": [
        "x_train=x_train.to_numpy()\n",
        "x_val=x_val.to_numpy()\n",
        "y_train=y_train.to_numpy()\n",
        "y_val=y_val.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ioSCPiiQT6nc",
        "outputId": "4e7a669a-036d-42db-b489-f3a7cc5da0a8"
      },
      "source": [
        "x_train[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i feel sarcastic more often than not'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWyf22Hqc3b6",
        "outputId": "692be252-9600-465f-be4c-54ee869f88b5"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12800,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl_djslvELqS",
        "outputId": "68350a26-0055-4622-8552-3037ea4243a0"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 5 1 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wq58tX-lrtG"
      },
      "source": [
        "# Text Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooFR8I-hl-z6",
        "outputId": "b1e1ef39-a64b-49c3-8d8e-947f617fa6ac"
      },
      "source": [
        "import string\n",
        "import re\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3SL4Smtl-9J"
      },
      "source": [
        "stopwords_english = stopwords.words('english')\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQCBLYmLl-_4"
      },
      "source": [
        "def process_text(text):\n",
        "    '''\n",
        "    Input: \n",
        "        text: a string containing a text\n",
        "    Output:\n",
        "        text_clean: a list of words containing the processed text\n",
        "    \n",
        "    '''\n",
        "    # remove number \n",
        "    text = re.sub('[0-9]', '', text)\n",
        "    # remove stock market tickers like $GE\n",
        "    text = re.sub(r'\\$\\w*', '', text)\n",
        "    # remove old style text \"RT\"\n",
        "    text = re.sub(r'^RT[\\s]+', '', text)\n",
        "    # remove hyperlinks\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    text = re.sub(r'#', '', text)\n",
        "    # remove the dates like Mar 30 2013\n",
        "    text = re.sub('(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s\\d{2}\\s\\d{4}', ' ', text)\n",
        "    text = re.sub(r'//', '', text)\n",
        "    # tokenize texts\n",
        "    text_tokens = word_tokenize(text)\n",
        "    \n",
        "    text_clean = []\n",
        "    \n",
        "    for word in text_tokens:\n",
        "       if (word not in stopwords_english and # remove stopwords\n",
        "            word not in string.punctuation): # remove punctuation\n",
        "            text_clean.append(word)\n",
        "            #stem_word = stemmer.stem(word) # stemming word\n",
        "            #text_clean.append(stem_word)\n",
        "    \n",
        "    return  text_clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX7lBAV9pgEC"
      },
      "source": [
        "# LSTMs in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr4AvRhSVoOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5206a9d-4d38-4bcf-d7b0-a9ec9550cf3a"
      },
      "source": [
        "!pip install keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.initializers import glorot_uniform\n",
        "np.random.seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx_2G4ITq-0m"
      },
      "source": [
        "## upload word emebedding file on google drive\n",
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file, 'r') as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            curr_word = line[0]\n",
        "            words.add(curr_word)\n",
        "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
        "        \n",
        "        i = 1\n",
        "        words_to_index = {}\n",
        "        index_to_words = {}\n",
        "        for w in sorted(words):\n",
        "            words_to_index[w] = i\n",
        "            index_to_words[i] = w\n",
        "            i = i + 1\n",
        "    return words, words_to_index, index_to_words, word_to_vec_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ8yXwa4q-3w"
      },
      "source": [
        "words, word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlK3974YVoRU"
      },
      "source": [
        "def text_to_indices(X, word_to_index, max_len):\n",
        "    m = X.shape[0]                                   \n",
        "    \n",
        "    X_indices = np.zeros((m, max_len))\n",
        "    \n",
        "    for i in range(m):\n",
        "      processed_text = process_text(X[i])\n",
        "      j = 0\n",
        "      for w in processed_text:\n",
        "        if (w in words) & (j < max_len):\n",
        "          X_indices[i, j] = word_to_index[w]\n",
        "        j += 1 \n",
        "\n",
        "    return X_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAoTPzEvwId5"
      },
      "source": [
        "x_train_indices = text_to_indices(x_train, word_to_index, max_len = 20 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkgLKr9qwIhC",
        "outputId": "e0cbdb87-9aca-43d5-9519-3fe22cddca76"
      },
      "source": [
        "x_train_indices.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12800, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRtFwOsawIoN",
        "outputId": "aa9f850c-a717-4ca4-90d3-6c7f425739b2"
      },
      "source": [
        "x_train_indices[45]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([385595., 219372.,  90668.,      0.,      0.,      0.,      0.,\n",
              "            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
              "            0.,      0.,      0.,      0.,      0.,      0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R98azIBH-RUp"
      },
      "source": [
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)]\n",
        "    return Y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi9bASBl-RXg"
      },
      "source": [
        "y_train_oh = convert_to_one_hot(y_train, 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTVZD0u9wIxL"
      },
      "source": [
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "   \n",
        "    vocab_len = len(word_to_index)+1                 \n",
        "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      \n",
        "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
        "    \n",
        "    for word, index in word_to_index.items():\n",
        "        emb_matrix[index, :] = word_to_vec_map[word]\n",
        "\n",
        "    embedding_layer = Embedding(vocab_len, emb_dim, trainable = False)\n",
        "    embedding_layer.build((None,))\n",
        "    embedding_layer.set_weights([emb_matrix])\n",
        "    \n",
        "    return embedding_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_p2xOPf2T6b"
      },
      "source": [
        "def lstm_model(input_shape, word_to_vec_map, word_to_index):\n",
        "\n",
        "    text_to_indices = Input(input_shape, dtype = 'int32')\n",
        "\n",
        "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "    \n",
        "    embeddings = embedding_layer(text_to_indices)   \n",
        "    \n",
        "    X = LSTM(128, return_sequences=True)(embeddings)\n",
        "    \n",
        "    X = Dropout(0.5)(X)\n",
        "    \n",
        "    X = LSTM(128, return_sequences=False)(X)\n",
        "    \n",
        "    X = Dropout(0.5)(X)\n",
        "    \n",
        "    X = Dense(6)(X)\n",
        "    \n",
        "    X = Activation('softmax')(X)\n",
        "    \n",
        "    model = Model(inputs = text_to_indices, outputs = X)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3ZEJS9J2T9f",
        "outputId": "cfbc2f7a-f33b-4c62-f3e2-11bbc57fdfb9"
      },
      "source": [
        "max_len= 20\n",
        "model = lstm_model((max_len,), word_to_vec_map, word_to_index)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 20, 50)            20000050  \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 20, 128)           91648     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 20, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 774       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 6)                 0         \n",
            "=================================================================\n",
            "Total params: 20,224,056\n",
            "Trainable params: 224,006\n",
            "Non-trainable params: 20,000,050\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UElXKBmaaMlT"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSYpWujJcGNv",
        "outputId": "23d0d824-25b9-4515-d6d8-623256b9c67c"
      },
      "source": [
        "model.fit(x_train_indices, y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "400/400 [==============================] - 22s 47ms/step - loss: 1.4580 - accuracy: 0.4329\n",
            "Epoch 2/50\n",
            "400/400 [==============================] - 19s 47ms/step - loss: 1.1236 - accuracy: 0.5799\n",
            "Epoch 3/50\n",
            "400/400 [==============================] - 19s 46ms/step - loss: 0.8918 - accuracy: 0.6747\n",
            "Epoch 4/50\n",
            "400/400 [==============================] - 18s 46ms/step - loss: 0.6984 - accuracy: 0.7494\n",
            "Epoch 5/50\n",
            "400/400 [==============================] - 19s 46ms/step - loss: 0.5431 - accuracy: 0.8070\n",
            "Epoch 6/50\n",
            "400/400 [==============================] - 19s 47ms/step - loss: 0.4541 - accuracy: 0.8375\n",
            "Epoch 7/50\n",
            "400/400 [==============================] - 19s 46ms/step - loss: 0.3578 - accuracy: 0.8741\n",
            "Epoch 8/50\n",
            "400/400 [==============================] - 18s 46ms/step - loss: 0.3236 - accuracy: 0.8798\n",
            "Epoch 9/50\n",
            "400/400 [==============================] - 19s 46ms/step - loss: 0.2742 - accuracy: 0.8974\n",
            "Epoch 10/50\n",
            "400/400 [==============================] - 19s 47ms/step - loss: 0.2402 - accuracy: 0.9090\n",
            "Epoch 11/50\n",
            "400/400 [==============================] - 18s 46ms/step - loss: 0.2106 - accuracy: 0.9190\n",
            "Epoch 12/50\n",
            "400/400 [==============================] - 19s 46ms/step - loss: 0.1827 - accuracy: 0.9282\n",
            "Epoch 13/50\n",
            "400/400 [==============================] - 18s 46ms/step - loss: 0.1675 - accuracy: 0.9359\n",
            "Epoch 14/50\n",
            "400/400 [==============================] - 18s 46ms/step - loss: 0.1577 - accuracy: 0.9374\n",
            "Epoch 15/50\n",
            "400/400 [==============================] - 19s 47ms/step - loss: 0.1378 - accuracy: 0.9448\n",
            "Epoch 16/50\n",
            "400/400 [==============================] - 19s 46ms/step - loss: 0.1223 - accuracy: 0.9538\n",
            "Epoch 17/50\n",
            "400/400 [==============================] - 18s 46ms/step - loss: 0.1277 - accuracy: 0.9482\n",
            "Epoch 18/50\n",
            "400/400 [==============================] - 18s 46ms/step - loss: 0.1083 - accuracy: 0.9585\n",
            "Epoch 19/50\n",
            "400/400 [==============================] - 19s 47ms/step - loss: 0.1234 - accuracy: 0.9526\n",
            "Epoch 20/50\n",
            "400/400 [==============================] - 19s 46ms/step - loss: 0.0943 - accuracy: 0.9649\n",
            "Epoch 21/50\n",
            "400/400 [==============================] - 19s 47ms/step - loss: 0.0721 - accuracy: 0.9714\n",
            "Epoch 22/50\n",
            "400/400 [==============================] - 18s 46ms/step - loss: 0.0822 - accuracy: 0.9699\n",
            "Epoch 23/50\n",
            "400/400 [==============================] - 19s 47ms/step - loss: 0.0778 - accuracy: 0.9695\n",
            "Epoch 24/50\n",
            "400/400 [==============================] - 19s 47ms/step - loss: 0.0868 - accuracy: 0.9653\n",
            "Epoch 25/50\n",
            "400/400 [==============================] - 19s 47ms/step - loss: 0.0680 - accuracy: 0.9755\n",
            "Epoch 26/50\n",
            "400/400 [==============================] - 19s 47ms/step - loss: 0.0650 - accuracy: 0.9766\n",
            "Epoch 27/50\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 0.0665 - accuracy: 0.9738\n",
            "Epoch 28/50\n",
            "400/400 [==============================] - 18s 44ms/step - loss: 0.0569 - accuracy: 0.9772\n",
            "Epoch 29/50\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 0.0567 - accuracy: 0.9802\n",
            "Epoch 30/50\n",
            "400/400 [==============================] - 18s 44ms/step - loss: 0.0572 - accuracy: 0.9800\n",
            "Epoch 31/50\n",
            "400/400 [==============================] - 18s 44ms/step - loss: 0.0501 - accuracy: 0.9800\n",
            "Epoch 32/50\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 0.0460 - accuracy: 0.9813\n",
            "Epoch 33/50\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 0.0437 - accuracy: 0.9843\n",
            "Epoch 34/50\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 0.0550 - accuracy: 0.9789\n",
            "Epoch 35/50\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 0.0502 - accuracy: 0.9855\n",
            "Epoch 36/50\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 0.0365 - accuracy: 0.9874\n",
            "Epoch 37/50\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 0.0450 - accuracy: 0.9850\n",
            "Epoch 38/50\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 0.0552 - accuracy: 0.9813\n",
            "Epoch 39/50\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 0.0375 - accuracy: 0.9888\n",
            "Epoch 40/50\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 0.0424 - accuracy: 0.9862\n",
            "Epoch 41/50\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 0.0425 - accuracy: 0.9854\n",
            "Epoch 42/50\n",
            "400/400 [==============================] - 19s 46ms/step - loss: 0.0271 - accuracy: 0.9894\n",
            "Epoch 43/50\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 0.0334 - accuracy: 0.9882\n",
            "Epoch 44/50\n",
            "400/400 [==============================] - 18s 46ms/step - loss: 0.0401 - accuracy: 0.9868\n",
            "Epoch 45/50\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 0.0299 - accuracy: 0.9908\n",
            "Epoch 46/50\n",
            "400/400 [==============================] - 18s 45ms/step - loss: 0.0309 - accuracy: 0.9899\n",
            "Epoch 47/50\n",
            "400/400 [==============================] - 18s 44ms/step - loss: 0.0309 - accuracy: 0.9880\n",
            "Epoch 48/50\n",
            "400/400 [==============================] - 18s 44ms/step - loss: 0.0283 - accuracy: 0.9896\n",
            "Epoch 49/50\n",
            "400/400 [==============================] - 18s 46ms/step - loss: 0.0270 - accuracy: 0.9892\n",
            "Epoch 50/50\n",
            "400/400 [==============================] - 18s 46ms/step - loss: 0.0227 - accuracy: 0.9919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f562f7ec610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWFT081GpySJ",
        "outputId": "111f92cb-455b-4ea2-9ca0-5010de051fc9"
      },
      "source": [
        "X_val_indices = text_to_indices(x_val, word_to_index, max_len = 20)\n",
        "Y_val_oh = convert_to_one_hot(y_val, C = 6)\n",
        "loss, acc = model.evaluate(X_val_indices, Y_val_oh)\n",
        "\n",
        "print(\"validation accuracy = \", acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 2s 16ms/step - loss: 0.8961 - accuracy: 0.8566\n",
            "validation accuracy =  0.8565624952316284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy8JMWIzoYtd"
      },
      "source": [
        "# Test your own sentence "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqaOKgwApyVd",
        "outputId": "0a016e72-ae1f-4e94-bece-4edb95f695d9"
      },
      "source": [
        "## Predict emotion \n",
        "input_string = np.array(['i am getting butterflies in my stomach'])\n",
        "X = text_to_indices(input_string, word_to_index, max_len = 20)\n",
        "prediction = np.argmax(model.predict(X))\n",
        "labels = {'sadness': 0, 'anger': 1, 'love': 2, 'surprise': 3, 'fear': 4, 'joy': 5}\n",
        "for key, value in labels.items():\n",
        "  if prediction == value:\n",
        "    print(\"predicted emotion is: \" + str(key))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted emotion is: fear\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaFh__vdtONx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcyr1Ru_tOQc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}