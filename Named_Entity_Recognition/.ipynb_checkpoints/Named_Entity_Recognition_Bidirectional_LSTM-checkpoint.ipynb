{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "doGOemX5kkmZ",
    "outputId": "d226d20b-276a-4840-ce7f-851775349b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Emotions.txt\t   ner_dataset.csv\t\t   special_tokens_map.json\n",
      "glove.6B.200d.txt  NHC_data_Biju.xlsx\t\t   theta.txt\n",
      "glove.6B.50d.txt   Quora_question_pairs_test.csv   tokenizer_config.json\n",
      "ner.csv\t\t   Quora_question_pairs_train.csv  vocab.txt\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/DATA\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "u4cl7qSN6SwY",
    "outputId": "54e13207-20d6-432b-df15-f4951514ca4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: Keras 2.4.3\n",
      "Uninstalling Keras-2.4.3:\n",
      "  Successfully uninstalled Keras-2.4.3\n",
      "Collecting keras==2.2.4\n",
      "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
      "\u001b[K     |████████████████████████████████| 312 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /Users/hemant./opt/anaconda3/lib/python3.8/site-packages (from keras==2.2.4) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/hemant./opt/anaconda3/lib/python3.8/site-packages (from keras==2.2.4) (1.1.2)\n",
      "Requirement already satisfied: pyyaml in /Users/hemant./opt/anaconda3/lib/python3.8/site-packages (from keras==2.2.4) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/hemant./opt/anaconda3/lib/python3.8/site-packages (from keras==2.2.4) (1.19.2)\n",
      "Requirement already satisfied: h5py in /Users/hemant./opt/anaconda3/lib/python3.8/site-packages (from keras==2.2.4) (2.10.0)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 7.4 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /Users/hemant./opt/anaconda3/lib/python3.8/site-packages (from keras==2.2.4) (1.15.0)\n",
      "Installing collected packages: keras-applications, keras\n",
      "Successfully installed keras-2.2.4 keras-applications-1.0.8\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/Users/hemant./opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Found existing installation: tensorflow 2.2.0\n",
      "Uninstalling tensorflow-2.2.0:\n",
      "  Successfully uninstalled tensorflow-2.2.0\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.13.1\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow==1.13.1\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/Users/hemant./opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
      "  Cloning https://www.github.com/keras-team/keras-contrib.git to /private/var/folders/1_/5jmrsdkn5zjfcj8_nmbnx2t80000gn/T/pip-req-build-28af5p1k\n",
      "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /private/var/folders/1_/5jmrsdkn5zjfcj8_nmbnx2t80000gn/T/pip-req-build-28af5p1k\n",
      "Requirement already satisfied: keras in /Users/hemant./opt/anaconda3/lib/python3.8/site-packages (from keras-contrib==2.0.8) (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/hemant./opt/anaconda3/lib/python3.8/site-packages (from keras->keras-contrib==2.0.8) (1.19.2)\n",
      "Requirement already satisfied: h5py in /Users/hemant./opt/anaconda3/lib/python3.8/site-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/hemant./opt/anaconda3/lib/python3.8/site-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/hemant./opt/anaconda3/lib/python3.8/site-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/hemant./opt/anaconda3/lib/python3.8/site-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/hemant./opt/anaconda3/lib/python3.8/site-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
      "Requirement already satisfied: pyyaml in /Users/hemant./opt/anaconda3/lib/python3.8/site-packages (from keras->keras-contrib==2.0.8) (5.3.1)\n",
      "Building wheels for collected packages: keras-contrib\n",
      "  Building wheel for keras-contrib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101064 sha256=fff59f06c5e8807164a25641d771a6511169199c532c17218a6f6d9c950aa6b1\n",
      "  Stored in directory: /private/var/folders/1_/5jmrsdkn5zjfcj8_nmbnx2t80000gn/T/pip-ephem-wheel-cache-9d91acsj/wheels/67/d2/f4/96ae3c3c62d1e05abfc8860ad0c1207794726d44ebbbb547f3\n",
      "Successfully built keras-contrib\n",
      "Installing collected packages: keras-contrib\n",
      "Successfully installed keras-contrib-2.0.8\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/Users/hemant./opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall keras -y\n",
    "!pip install keras==2.2.4\n",
    "\n",
    "!pip uninstall tensorflow -y\n",
    "!pip install tensorflow==1.13.1\n",
    "\n",
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "WmvOalFbs2WL",
    "outputId": "0a2fa637-a45b-4042-be32-67684b111167"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-10bf4406e827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow \n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import keras as k\n",
    "from keras_contrib.layers import CRF\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNAMfp3p1UET"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bOpAFgtkksjV"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ner_dataset.csv', encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "FUWTPIz8ksy1",
    "outputId": "f40aa57f-6b28-4e2d-e001-1c6ed930389d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nx4U6B2eqkDt",
    "outputId": "89cf5db1-49fa-4167-de3d-1061a91e12f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        887908\n",
       "B-geo     37644\n",
       "B-tim     20333\n",
       "B-org     20143\n",
       "I-per     17251\n",
       "B-per     16990\n",
       "I-org     16784\n",
       "B-gpe     15870\n",
       "I-geo      7414\n",
       "I-tim      6528\n",
       "B-art       402\n",
       "B-eve       308\n",
       "I-art       297\n",
       "I-eve       253\n",
       "B-nat       201\n",
       "I-gpe       198\n",
       "I-nat        51\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UmVu7Sv1fG5"
   },
   "source": [
    "# Extract mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "C0VxQ7Z6lP9s"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def get_dict_map(data, token_or_tag):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    \n",
    "    if token_or_tag == 'token':\n",
    "        n=2\n",
    "        vocab = list(set(data['Word'].to_list()))\n",
    "    else:\n",
    "        n=0\n",
    "        vocab = list(set(data['Tag'].to_list()))\n",
    "\n",
    "\n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab, n)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab, n)}\n",
    "    return tok2idx, idx2tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1YGvBLrHlYOa"
   },
   "outputs": [],
   "source": [
    "token2idx, idx2token = get_dict_map(df, 'token')\n",
    "tag2idx, idx2tag = get_dict_map(df, 'tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mKvaPo8r3wJm"
   },
   "outputs": [],
   "source": [
    "token2idx['<PAD>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oUdsc4rD3wQ3",
    "outputId": "42d24b29-17e5-443d-94f6-c7c6edf34ed5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(token2idx['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_2fD4vVGwoJn"
   },
   "outputs": [],
   "source": [
    "idx2token[1] = '<PAD>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9Ln8WshwRwJ",
    "outputId": "c9eacd2e-a295-4794-f452-5602c18f3248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD>\n"
     ]
    }
   ],
   "source": [
    "print(idx2token[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "c1mjoDlZ4zmS"
   },
   "outputs": [],
   "source": [
    "token2idx['UNK'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLgnrk5z4zpS",
    "outputId": "068f25d2-766f-48d8-b03f-9d1f585f2e83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(token2idx['UNK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Qbw2n2kk4zsG"
   },
   "outputs": [],
   "source": [
    "idx2token[0] = '<UNK>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KMOMMgD94zvC",
    "outputId": "6327d633-ddfa-4d0a-a7db-2862aa8ef673"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK>\n"
     ]
    }
   ],
   "source": [
    "print(idx2token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "YSi3hamylYXe",
    "outputId": "4e626681-c44f-43c6-8c82-d4e1ada2b1ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>32377</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>24775</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>28202</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>1991</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>2706</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag  Word_idx  Tag_idx\n",
       "0  Sentence: 1      Thousands  NNS   O     32377        7\n",
       "1          NaN             of   IN   O     24775        7\n",
       "2          NaN  demonstrators  NNS   O     28202        7\n",
       "3          NaN           have  VBP   O      1991        7\n",
       "4          NaN        marched  VBN   O      2706        7"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Word_idx'] = df['Word'].map(token2idx)\n",
    "df['Tag_idx'] = df['Tag'].map(tag2idx)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "onbSUp4mpG-7"
   },
   "outputs": [],
   "source": [
    "df_fill = df.fillna(method='ffill', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "y-9Eh6dipWKU",
    "outputId": "592caca9-2fb7-4b5c-a1ec-e8e025862e5d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>32377</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>24775</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>28202</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>1991</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>2706</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag  Word_idx  Tag_idx\n",
       "0  Sentence: 1      Thousands  NNS   O     32377        7\n",
       "1  Sentence: 1             of   IN   O     24775        7\n",
       "2  Sentence: 1  demonstrators  NNS   O     28202        7\n",
       "3  Sentence: 1           have  VBP   O      1991        7\n",
       "4  Sentence: 1        marched  VBN   O      2706        7"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fill.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBpKPh4fpipt",
    "outputId": "2d223555-eb46-488a-cfa6-b753b0daffd0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_group = df_fill.groupby(['Sentence #'],as_index=False)['Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "8s9eHeSJp8bg",
    "outputId": "d224dc90-a8f3-4204-891c-abb2e484e2c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "      <td>[32377, 24775, 28202, 1991, 2706, 4954, 15242,...</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 8, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
       "      <td>[JJ, NNS, VBP, PRP, VBP, TO, VB, NN, TO, JJ, J...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[23249, 21361, 13251, 9151, 4551, 17430, 19255...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
       "      <td>[NN, NNS, NNP, VBD, JJ, NNS, IN, DT, NNP, JJ, ...</td>\n",
       "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...</td>\n",
       "      <td>[24439, 28588, 1921, 11479, 23363, 3726, 5702,...</td>\n",
       "      <td>[7, 7, 0, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 11,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
       "      <td>[PRP, VBD, IN, DT, NN, JJ, NN, IN, NN, NNS, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[5442, 9894, 13443, 7327, 23747, 30393, 20888,...</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[U.N., relief, coordinator, Jan, Egeland, said...</td>\n",
       "      <td>[NNP, NN, NN, NNP, NNP, VBD, NNP, ,, NNP, ,, J...</td>\n",
       "      <td>[B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...</td>\n",
       "      <td>[4674, 2385, 19748, 29084, 3998, 20833, 28076,...</td>\n",
       "      <td>[8, 7, 7, 2, 12, 7, 0, 7, 8, 7, 4, 7, 4, 7, 7,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #  ...                                            Tag_idx\n",
       "0      Sentence: 1  ...  [7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 8, 7, 7, ...\n",
       "1     Sentence: 10  ...  [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...\n",
       "2    Sentence: 100  ...  [7, 7, 0, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 11,...\n",
       "3   Sentence: 1000  ...                  [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
       "4  Sentence: 10000  ...  [8, 7, 7, 2, 12, 7, 0, 7, 8, 7, 4, 7, 4, 7, 7,...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8-a86mb1pRv"
   },
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S11G3StIqTAJ",
    "outputId": "9887384e-5afb-4bc3-e75a-1ce22fa0e575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tokens length: 43163 \n",
      "test_tokens length: 4796 \n",
      "train_tags: 43163 \n",
      "test_tags: 4796\n"
     ]
    }
   ],
   "source": [
    "def get_pad_train_test_val(data_group, data):\n",
    "\n",
    "    #get max token and tag length\n",
    "    n_token = len(list(set(data['Word'].to_list())))\n",
    "    n_tag = len(list(set(data['Tag'].to_list())))\n",
    "\n",
    "    #Pad tokens (X var)    \n",
    "    tokens = data_group['Word_idx'].tolist()\n",
    "    maxlen = max([len(s) for s in tokens])\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= token2idx['<PAD>'])\n",
    "\n",
    "    #Pad Tags (y var) and convert it into one hot encoding\n",
    "    tags = data_group['Tag_idx'].tolist()\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag2idx[\"O\"])\n",
    "    n_tags = len(tag2idx)\n",
    "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
    "    \n",
    "    #Split train, test and validation set\n",
    "    train_tokens, test_tokens, train_tags, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n",
    "    \n",
    "\n",
    "    print(\n",
    "        'train_tokens length:', len(train_tokens),\n",
    "        '\\ntest_tokens length:', len(test_tokens),\n",
    "        '\\ntrain_tags:', len(train_tags),\n",
    "        '\\ntest_tags:', len(test_tags),\n",
    "    )\n",
    "    \n",
    "    return train_tokens, test_tokens, train_tags, test_tags\n",
    "\n",
    "train_tokens, test_tokens, train_tags, test_tags = get_pad_train_test_val(df_group, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wA1CvnMFvqtN",
    "outputId": "82eda4dc-6a6f-454c-dcf9-dabcc92e9cf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43163, 104)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YKeL4euNvqwI",
    "outputId": "a1f16ac1-c237-4ad7-94ff-993afa1286f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17652, 13251, 26623, 34919, 27171,  3121, 17430,  3924, 26425,\n",
       "       13221,  2788, 27105,  9151, 25406, 23937, 25063, 29180,  4874,\n",
       "       12173,  8715,  5702, 19851, 26764, 34479, 25979, 30217, 24147,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "em-lBp9jzrlE",
    "outputId": "9bd567e1-bac5-44fa-e272-e852654b1fdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tags[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1PqwmTLBrJo"
   },
   "source": [
    "# Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L01pZfXeqt5z",
    "outputId": "e591bdf2-4fc9-4a80-e8d4-5aedc9fe9bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(k.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aNYfagda1J8U",
    "outputId": "6202e18b-b662-439d-8c14-f7a35e0ada8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  35181 \n",
      "output_dim:  64 \n",
      "input_length:  104 \n",
      "n_tags:  17\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(list(set(df['Word'].to_list())))+3\n",
    "output_dim = 64\n",
    "input_length = max([len(s) for s in df_group['Word_idx'].tolist()])\n",
    "n_tags = len(tag2idx)\n",
    "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "say3GY-s1J_A"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
    "model.add(Bidirectional(LSTM(units=64, \n",
    "                           return_sequences=True, \n",
    "                           dropout=0.5, \n",
    "                           recurrent_dropout=0.5, \n",
    "                           kernel_initializer=k.initializers.he_normal())))\n",
    "model.add(LSTM(units=128, return_sequences=True, recurrent_dropout=0.1))\n",
    "model.add(TimeDistributed(Dense(n_tags, activation=\"relu\")))\n",
    "crf = CRF(n_tags)\n",
    "model.add(crf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V8zr7gh3olQ4",
    "outputId": "e3145ed2-2fc4-4543-f222-f6c891901dce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 104, 64)           2251584   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 104, 128)          66048     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 104, 128)          131584    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 104, 17)           2193      \n",
      "=================================================================\n",
      "Total params: 2,451,409\n",
      "Trainable params: 2,451,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "nuJ3hmHzeeyQ"
   },
   "outputs": [],
   "source": [
    "lr_schedule = k.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.3,\n",
    "    decay_steps=500,\n",
    "    decay_rate=0.9)\n",
    "#optimizer = k.optimizers.SGD(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "uLYkrhwqesEG"
   },
   "outputs": [],
   "source": [
    "Adam = tensorflow.keras.optimizers.Adam(\n",
    "    learning_rate=lr_schedule,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name=\"Adam\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 970
    },
    "id": "UX34qdR41KBk",
    "outputId": "30c6f6c4-792e-491d-8f6c-72461f8f7286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "85/85 [==============================] - 281s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 2/20\n",
      "85/85 [==============================] - 271s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 3/20\n",
      "85/85 [==============================] - 273s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 4/20\n",
      "85/85 [==============================] - 271s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 5/20\n",
      "85/85 [==============================] - 269s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 6/20\n",
      "85/85 [==============================] - 269s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 7/20\n",
      "85/85 [==============================] - 271s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 8/20\n",
      "85/85 [==============================] - 271s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 9/20\n",
      "85/85 [==============================] - 271s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 10/20\n",
      "85/85 [==============================] - 271s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 11/20\n",
      "85/85 [==============================] - 268s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 12/20\n",
      "85/85 [==============================] - 269s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 13/20\n",
      "85/85 [==============================] - 270s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 14/20\n",
      "85/85 [==============================] - 271s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 15/20\n",
      "85/85 [==============================] - 268s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 16/20\n",
      "85/85 [==============================] - 267s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 17/20\n",
      "85/85 [==============================] - 267s 3s/step - loss: 0.5195 - accuracy: 0.9678\n",
      "Epoch 18/20\n",
      "57/85 [===================>..........] - ETA: 1:28 - loss: 0.5213 - accuracy: 0.9677"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-231984b39710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model.compile(optimizer=Adam, loss=crf_layer.loss_function, metrics=[crf_layer.accuracy])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model.compile(optimizer=Adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.compile(optimizer=Adam, loss=crf_layer.loss_function, metrics=[crf_layer.accuracy])\n",
    "model.fit(train_tokens, np.array(train_tags), batch_size=512, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJSZTLEmGSZy",
    "outputId": "42019333-83af-4f57-f04f-fa30cb01a9d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 12s 72ms/step - loss: 0.5162 - accuracy: 0.9680\n",
      "test accuracy =  0.9679760932922363\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_tokens, np.array(test_tags))\n",
    "print(\"test accuracy = \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47s6tdUABWXy",
    "outputId": "de62eced-42ae-4403-8bf4-269936b81c90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           ||True ||Pred\n",
      "==============================\n",
      "Anderson       : O     O\n",
      "mis-2009       : O     O\n",
      "Saudi-owned    : B-tim O\n",
      "Mahdist        : O     O\n",
      "lays           : B-geo O\n",
      "Zablocki       : O     O\n",
      "Schrock        : O     O\n",
      "grips          : O     O\n",
      "deadlocked     : O     O\n",
      "olive-green    : O     O\n",
      "dearest        : O     O\n",
      "el-Sibaie      : O     O\n",
      "Mahdist        : O     O\n",
      "fundamentals   : O     O\n",
      "boxing         : O     O\n",
      "Live           : O     O\n",
      "Juvenal        : O     O\n",
      "Pluto          : O     O\n",
      "brutality      : O     O\n",
      "lawmakers      : O     O\n",
      "umbrella       : O     O\n",
      "semblance      : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n",
      "<UNK>          : O     O\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "p = model.predict(np.array([test_tokens[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "true = np.argmax(np.array(test_tags)[i], -1)\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(test_tokens[i], true, p[0]):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(idx2token[w-1], idx2tag[t], idx2tag[pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnQbdKa-QZZ_"
   },
   "source": [
    "# Testing with your own sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "PbcFz1RwJDzX"
   },
   "outputs": [],
   "source": [
    "def predict(sentence, model, vocab = token2idx, tag_map = tag2idx):\n",
    "    x_test_sent = pad_sequences(sequences=[[token2idx.get(token, 0) for token in sentence.split(' ')]], padding=\"post\", value=0, maxlen=input_length)\n",
    "    p = model.predict(np.array([x_test_sent[0]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    print(\"{:15}||{}\".format(\"Word\", \"Prediction\"))\n",
    "    print(30 * \"=\")\n",
    "    for w, pred in zip(sentence.split(' '), p[0]):\n",
    "      print(\"{:15}: {:5}\".format(w, idx2tag[pred])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nnbkAsumu8k4",
    "outputId": "bfa88ae8-eb53-45b3-f64c-7fa4468e1dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           ||Prediction\n",
      "==============================\n",
      "In             : O    \n",
      "the            : O    \n",
      "context        : O    \n",
      "of             : O    \n",
      "prehistory,    : O    \n",
      "antiquity      : O    \n",
      "and            : O    \n",
      "contemporary   : O    \n",
      "indigenous     : O    \n",
      "peoples,       : O    \n",
      "the            : O    \n",
      "title          : O    \n",
      "may            : O    \n",
      "refer          : O    \n",
      "to             : O    \n",
      "tribal         : O    \n",
      "kingship.      : O    \n",
      "Germanic       : O    \n",
      "kingship       : O    \n",
      "is             : O    \n",
      "cognate        : O    \n",
      "with           : O    \n",
      "Indo-European  : O    \n",
      "traditions     : O    \n",
      "of             : O    \n",
      "tribal         : O    \n",
      "rulership      : O    \n"
     ]
    }
   ],
   "source": [
    "sentence = \"In the context of prehistory, antiquity and contemporary indigenous peoples, the title may refer to tribal kingship. Germanic kingship is cognate with Indo-European traditions of tribal rulership\"\n",
    "predictions = predict(sentence, model, token2idx , tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iy_TH2fY5uyG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Named_Entity_Recognition_Bidirectional_LSTM.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
