{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Named_Entity_Recognition_Bidirectional_LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doGOemX5kkmZ",
        "outputId": "de528af6-0a91-426b-ca21-9275155f10fe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/DATA\")\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Emotions.txt\t   glove.6B.50d.txt  ner.csv\t      theta.txt\n",
            "glove.6B.200d.txt  model.png\t     ner_dataset.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNAMfp3p1UET"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOpAFgtkksjV"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('ner_dataset.csv', encoding= 'unicode_escape')\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FUWTPIz8ksy1",
        "outputId": "89a99db5-6022-46c5-c3bc-749c9e0a915f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1          NaN             of   IN   O\n",
              "2          NaN  demonstrators  NNS   O\n",
              "3          NaN           have  VBP   O\n",
              "4          NaN        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UmVu7Sv1fG5"
      },
      "source": [
        "# Extract mappings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0VxQ7Z6lP9s"
      },
      "source": [
        "from itertools import chain\n",
        "def get_dict_map(data, token_or_tag):\n",
        "    tok2idx = {}\n",
        "    idx2tok = {}\n",
        "    \n",
        "    if token_or_tag == 'token':\n",
        "        vocab = list(set(data['Word'].to_list()))\n",
        "    else:\n",
        "        vocab = list(set(data['Tag'].to_list()))\n",
        "    \n",
        "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
        "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
        "    return tok2idx, idx2tok"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YGvBLrHlYOa"
      },
      "source": [
        "token2idx, idx2token = get_dict_map(df, 'token')\n",
        "tag2idx, idx2tag = get_dict_map(df, 'tag')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKvaPo8r3wJm"
      },
      "source": [
        "token2idx['<PAD>'] = len(list(set(df['Word'].to_list())))+1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUdsc4rD3wQ3",
        "outputId": "2c8ee7bc-278f-4191-ba49-9c06bdf45611"
      },
      "source": [
        "print(token2idx['<PAD>'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2fD4vVGwoJn"
      },
      "source": [
        "idx2token[35178] = '<PAD>'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9Ln8WshwRwJ",
        "outputId": "bb30c4eb-dc4b-4c57-d224-275740543cc7"
      },
      "source": [
        "print(idx2token[35178])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1mjoDlZ4zmS"
      },
      "source": [
        "token2idx['UNK'] = len(list(set(df['Word'].to_list())))+2"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLgnrk5z4zpS",
        "outputId": "4987367b-0fde-4401-f99e-854605a82a84"
      },
      "source": [
        "print(token2idx['UNK'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbw2n2kk4zsG"
      },
      "source": [
        "idx2token[35179] = '<PAD>'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMOMMgD94zvC",
        "outputId": "30bc49d8-84d5-435f-d93e-d36539d1d620"
      },
      "source": [
        "print(idx2token[35179])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "YSi3hamylYXe",
        "outputId": "1422783d-18db-4475-efab-0844e0666eaa"
      },
      "source": [
        "df['Word_idx'] = df['Word'].map(token2idx)\n",
        "df['Tag_idx'] = df['Tag'].map(tag2idx)\n",
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Word_idx</th>\n",
              "      <th>Tag_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>2444</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>10670</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>7679</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "      <td>5362</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "      <td>7464</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag  Word_idx  Tag_idx\n",
              "0  Sentence: 1      Thousands  NNS   O      2444        1\n",
              "1          NaN             of   IN   O     10670        1\n",
              "2          NaN  demonstrators  NNS   O      7679        1\n",
              "3          NaN           have  VBP   O      5362        1\n",
              "4          NaN        marched  VBN   O      7464        1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onbSUp4mpG-7"
      },
      "source": [
        "df_fill = df.fillna(method='ffill', axis=0)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "y-9Eh6dipWKU",
        "outputId": "29f0ec87-4d23-4293-89f2-ce62ca5b56fb"
      },
      "source": [
        "df_fill.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Word_idx</th>\n",
              "      <th>Tag_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>2444</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>10670</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>7679</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "      <td>5362</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "      <td>7464</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag  Word_idx  Tag_idx\n",
              "0  Sentence: 1      Thousands  NNS   O      2444        1\n",
              "1  Sentence: 1             of   IN   O     10670        1\n",
              "2  Sentence: 1  demonstrators  NNS   O      7679        1\n",
              "3  Sentence: 1           have  VBP   O      5362        1\n",
              "4  Sentence: 1        marched  VBN   O      7464        1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBpKPh4fpipt",
        "outputId": "3a05adbb-3723-45cd-fbe2-870e9dbbad90"
      },
      "source": [
        "df_group = df_fill.groupby(['Sentence #'],as_index=False)['Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "8s9eHeSJp8bg",
        "outputId": "9956d206-cf6b-4bd5-91e0-add50683428a"
      },
      "source": [
        "df_group.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Word_idx</th>\n",
              "      <th>Tag_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
              "      <td>[NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...</td>\n",
              "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
              "      <td>[2444, 10670, 7679, 5362, 7464, 25009, 25531, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 10</td>\n",
              "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
              "      <td>[JJ, NNS, VBP, PRP, VBP, TO, VB, NN, TO, JJ, J...</td>\n",
              "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[28742, 2655, 29064, 19335, 14707, 16913, 2035...</td>\n",
              "      <td>[13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 100</td>\n",
              "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
              "      <td>[NN, NNS, NNP, VBD, JJ, NNS, IN, DT, NNP, JJ, ...</td>\n",
              "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...</td>\n",
              "      <td>[21587, 13142, 27714, 16334, 11098, 6530, 4807...</td>\n",
              "      <td>[1, 1, 8, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1000</td>\n",
              "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
              "      <td>[PRP, VBD, IN, DT, NN, JJ, NN, IN, NN, NNS, .]</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[2780, 21402, 33583, 7831, 1168, 31223, 8058, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 10000</td>\n",
              "      <td>[U.N., relief, coordinator, Jan, Egeland, said...</td>\n",
              "      <td>[NNP, NN, NN, NNP, NNP, VBD, NNP, ,, NNP, ,, J...</td>\n",
              "      <td>[B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...</td>\n",
              "      <td>[9123, 32170, 8197, 14705, 2800, 21084, 3681, ...</td>\n",
              "      <td>[3, 1, 1, 5, 6, 1, 8, 1, 3, 1, 13, 1, 13, 1, 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Sentence #  ...                                            Tag_idx\n",
              "0      Sentence: 1  ...  [1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, ...\n",
              "1     Sentence: 10  ...  [13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\n",
              "2    Sentence: 100  ...  [1, 1, 8, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, ...\n",
              "3   Sentence: 1000  ...                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
              "4  Sentence: 10000  ...  [3, 1, 1, 5, 6, 1, 8, 1, 3, 1, 13, 1, 13, 1, 1...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8-a86mb1pRv"
      },
      "source": [
        "# Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHwPyQ0rqMP9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S11G3StIqTAJ",
        "outputId": "5289736a-3887-44be-b54a-34af32a1264f"
      },
      "source": [
        "def get_pad_train_test_val(data_group, data):\n",
        "\n",
        "    #get max token and tag length\n",
        "    n_token = len(list(set(data['Word'].to_list())))\n",
        "    n_tag = len(list(set(data['Tag'].to_list())))\n",
        "\n",
        "    #Pad tokens (X var)    \n",
        "    tokens = data_group['Word_idx'].tolist()\n",
        "    maxlen = max([len(s) for s in tokens])\n",
        "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= token2idx['<PAD>'])\n",
        "\n",
        "    #Pad Tags (y var) and convert it into one hot encoding\n",
        "    tags = data_group['Tag_idx'].tolist()\n",
        "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag2idx[\"O\"])\n",
        "    n_tags = len(tag2idx)\n",
        "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
        "    \n",
        "    #Split train, test and validation set\n",
        "    train_tokens, test_tokens, train_tags, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n",
        "    \n",
        "\n",
        "    print(\n",
        "        'train_tokens length:', len(train_tokens),\n",
        "        '\\ntest_tokens length:', len(test_tokens),\n",
        "        '\\ntrain_tags:', len(train_tags),\n",
        "        '\\ntest_tags:', len(test_tags),\n",
        "    )\n",
        "    \n",
        "    return train_tokens, test_tokens, train_tags, test_tags\n",
        "\n",
        "train_tokens, test_tokens, train_tags, test_tags = get_pad_train_test_val(df_group, df)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_tokens length: 43163 \n",
            "test_tokens length: 4796 \n",
            "train_tags: 43163 \n",
            "test_tags: 4796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA1CvnMFvqtN",
        "outputId": "226f0ec2-d334-4c29-90f9-12b85a9a276b"
      },
      "source": [
        "train_tokens.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43163, 104)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKeL4euNvqwI",
        "outputId": "a3810a29-1714-49da-bdce-42eb86720edd"
      },
      "source": [
        "train_tokens[0]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  151, 29064, 14633,  6545,  8254,  4081, 16913,  8348, 28500,\n",
              "       24746, 27929, 26205, 19335, 33321,  1733, 16447, 12268, 18307,\n",
              "        3780, 15283,  4807,  7374,  6182, 25131,  1359, 17255, 25879,\n",
              "       35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179,\n",
              "       35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179,\n",
              "       35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179,\n",
              "       35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179,\n",
              "       35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179,\n",
              "       35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179,\n",
              "       35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179,\n",
              "       35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179,\n",
              "       35179, 35179, 35179, 35179, 35179], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em-lBp9jzrlE",
        "outputId": "9239da29-af4d-42e6-c705-f670708dc39c"
      },
      "source": [
        "train_tags[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1PqwmTLBrJo"
      },
      "source": [
        "# Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lCUKj2x1J29"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow \n",
        "from tensorflow.keras import Sequential, Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-Mxv2mg1J5w"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "tensorflow.random.set_seed(2)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNYfagda1J8U",
        "outputId": "cf1599ca-bfec-429f-e5c0-2834a875a465"
      },
      "source": [
        "input_dim = len(list(set(df['Word'].to_list())))+3\n",
        "output_dim = 64\n",
        "input_length = max([len(s) for s in df_group['Word_idx'].tolist()])\n",
        "n_tags = len(tag2idx)\n",
        "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_dim:  35181 \n",
            "output_dim:  64 \n",
            "input_length:  104 \n",
            "n_tags:  17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "say3GY-s1J_A"
      },
      "source": [
        "def get_bilstm_lstm_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add Embedding layer\n",
        "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
        "\n",
        "    # Add bidirectional LSTM\n",
        "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
        "\n",
        "    # Add LSTM\n",
        "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
        "\n",
        "    # Add timeDistributed Layer\n",
        "    model.add(TimeDistributed(Dense(n_tags, activation=\"relu\")))\n",
        "\n",
        "    #Optimiser \n",
        "    adam = tensorflow.keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "    return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX34qdR41KBk"
      },
      "source": [
        "def train_model(X, y, model):\n",
        "    loss = list()\n",
        "    for i in range(20):\n",
        "        hist = model.fit(X, y, batch_size=1000, verbose=1, epochs=1, validation_split=0.2)\n",
        "        loss.append(hist.history['loss'][0])\n",
        "    return loss"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvcfr3-jELUR",
        "outputId": "abb6cd01-3acb-4778-85a6-d851595ce8fd"
      },
      "source": [
        "results = pd.DataFrame()\n",
        "model_bilstm_lstm = get_bilstm_lstm_model()\n",
        "results['with_add_lstm'] = train_model(train_tokens, np.array(train_tags), model_bilstm_lstm)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 193s 5s/step - loss: 1.0350 - accuracy: 0.8568 - val_loss: 0.2737 - val_accuracy: 0.9679\n",
            "35/35 [==============================] - 185s 5s/step - loss: 0.2500 - accuracy: 0.9677 - val_loss: 0.2230 - val_accuracy: 0.9679\n",
            "35/35 [==============================] - 185s 5s/step - loss: 0.2215 - accuracy: 0.9677 - val_loss: 0.2036 - val_accuracy: 0.9679\n",
            "35/35 [==============================] - 184s 5s/step - loss: 0.2070 - accuracy: 0.9677 - val_loss: 0.1920 - val_accuracy: 0.9679\n",
            "35/35 [==============================] - 185s 5s/step - loss: 0.2186 - accuracy: 0.9677 - val_loss: 0.1747 - val_accuracy: 0.9679\n",
            "35/35 [==============================] - 185s 5s/step - loss: 0.1837 - accuracy: 0.9677 - val_loss: 0.1687 - val_accuracy: 0.9679\n",
            "35/35 [==============================] - 185s 5s/step - loss: 0.1910 - accuracy: 0.9677 - val_loss: 0.1890 - val_accuracy: 0.9679\n",
            "35/35 [==============================] - 185s 5s/step - loss: 0.1689 - accuracy: 0.9678 - val_loss: 0.1660 - val_accuracy: 0.9679\n",
            "35/35 [==============================] - 185s 5s/step - loss: 0.1602 - accuracy: 0.9678 - val_loss: 0.1593 - val_accuracy: 0.9680\n",
            "35/35 [==============================] - 185s 5s/step - loss: 0.1507 - accuracy: 0.9679 - val_loss: 0.1536 - val_accuracy: 0.9680\n",
            "35/35 [==============================] - 185s 5s/step - loss: 0.1457 - accuracy: 0.9680 - val_loss: 0.1522 - val_accuracy: 0.9680\n",
            "35/35 [==============================] - 184s 5s/step - loss: 0.1422 - accuracy: 0.9681 - val_loss: 0.1501 - val_accuracy: 0.9681\n",
            "35/35 [==============================] - 184s 5s/step - loss: 0.1383 - accuracy: 0.9684 - val_loss: 0.1270 - val_accuracy: 0.9684\n",
            "35/35 [==============================] - 185s 5s/step - loss: 0.1122 - accuracy: 0.9685 - val_loss: 0.1165 - val_accuracy: 0.9685\n",
            "35/35 [==============================] - 184s 5s/step - loss: 0.1021 - accuracy: 0.9685 - val_loss: 0.1093 - val_accuracy: 0.9686\n",
            "35/35 [==============================] - 184s 5s/step - loss: 0.1014 - accuracy: 0.9688 - val_loss: 0.1548 - val_accuracy: 0.9691\n",
            "35/35 [==============================] - 184s 5s/step - loss: 0.1076 - accuracy: 0.9689 - val_loss: 0.1119 - val_accuracy: 0.9694\n",
            "35/35 [==============================] - 184s 5s/step - loss: 0.0943 - accuracy: 0.9692 - val_loss: 0.1050 - val_accuracy: 0.9692\n",
            "35/35 [==============================] - 184s 5s/step - loss: 0.0876 - accuracy: 0.9694 - val_loss: 0.1055 - val_accuracy: 0.9696\n",
            "35/35 [==============================] - 184s 5s/step - loss: 0.0957 - accuracy: 0.9698 - val_loss: 0.1054 - val_accuracy: 0.9698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJSZTLEmGSZy",
        "outputId": "bf7293af-f3ce-43ee-c8b6-cbc88fca81d0"
      },
      "source": [
        "test_loss, test_acc = model_bilstm_lstm.evaluate(test_tokens, np.array(test_tags))\n",
        "print(\"test accuracy = \", test_acc)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150/150 [==============================] - 8s 55ms/step - loss: 0.1029 - accuracy: 0.9699\n",
            "test accuracy =  0.9698707461357117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47s6tdUABWXy",
        "outputId": "3ab31b94-75a2-4735-f8d1-4d612e178dd9"
      },
      "source": [
        "i = 75\n",
        "p = model_bilstm_lstm.predict([test_tokens[i]])\n",
        "p.shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(104, 1, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWl91f9kwDD0",
        "outputId": "050d7ff0-f7dd-42de-c10a-7f6228bdda10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "p = np.argmax(p, axis=-1)\n",
        "p.shape"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(104, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziR252Q0xVvR",
        "outputId": "1a484a71-8f47-433b-c5f8-882706b3aae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(p)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [5]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX3Lg0INwLMc",
        "outputId": "83029cc2-1f36-4b65-bc1e-0d6c03ea7ba0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "true = np.argmax(np.array(test_tags)[i], -1)\n",
        "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
        "print(30 * \"=\")\n",
        "for w, t, pred in zip(test_tokens[i], true, p[:,0]):\n",
        "    if w != 0:\n",
        "        print(\"{:15}: {:5} {}\".format(idx2token[w-1], idx2tag[t], idx2tag[pred]))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word           ||True ||Pred\n",
            "==============================\n",
            "Moustafa       : O     O\n",
            "Steven         : O     O\n",
            "lives          : O     O\n",
            "pedestrians    : O     O\n",
            "serpent        : O     O\n",
            "Suez           : O     O\n",
            "DEA            : O     O\n",
            "pedestrians    : O     O\n",
            "releases       : B-tim O\n",
            "immigration    : I-tim O\n",
            "once-a-decade  : I-tim O\n",
            "Chesnot        : I-tim B-per\n",
            "Moscow-led     : I-tim O\n",
            "Nomura         : O     O\n",
            "Pradip         : O     O\n",
            "Jonathan       : O     O\n",
            "Ericsson       : O     O\n",
            "pedestrians    : O     O\n",
            "sweep          : O     O\n",
            "once-a-decade  : O     O\n",
            "Pradip         : O     O\n",
            "Chairperson    : O     O\n",
            "Separatists    : O     O\n",
            "reacting       : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n",
            "<PAD>          : O     O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnQbdKa-QZZ_"
      },
      "source": [
        "# Testing with your own sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbcFz1RwJDzX"
      },
      "source": [
        "def predict(sentence, model, vocab = token2idx, tag_map = tag2idx):\n",
        "    x_test_sent = pad_sequences(sequences=[[token2idx.get(token, 0) for token in sentence.split(' ')]], padding=\"post\", value=0, maxlen=input_length)\n",
        "    p = model.predict(x_test_sent[0])\n",
        "    p = np.argmax(p, axis=-1)\n",
        "    print(\"{:15}||{}\".format(\"Word\", \"Prediction\"))\n",
        "    print(30 * \"=\")\n",
        "    for w, pred in zip(sentence.split(' '), p[:,0]):\n",
        "      print(\"{:15}: {:5}\".format(w, idx2tag[pred])) "
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnbkAsumu8k4",
        "outputId": "0f469df4-451b-4914-b980-b96f104bc049"
      },
      "source": [
        "sentence = \"In the context of prehistory, antiquity and contemporary indigenous peoples, the title may refer to tribal kingship. Germanic kingship is cognate with Indo-European traditions of tribal rulership\"\n",
        "predictions = predict(sentence, model_bilstm_lstm, token2idx , tag2idx)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 104) for input KerasTensor(type_spec=TensorSpec(shape=(None, 104), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
            "Word           ||Prediction\n",
            "==============================\n",
            "In             : O    \n",
            "the            : O    \n",
            "context        : O    \n",
            "of             : O    \n",
            "prehistory,    : B-per\n",
            "antiquity      : B-per\n",
            "and            : O    \n",
            "contemporary   : O    \n",
            "indigenous     : O    \n",
            "peoples,       : B-per\n",
            "the            : O    \n",
            "title          : O    \n",
            "may            : O    \n",
            "refer          : O    \n",
            "to             : O    \n",
            "tribal         : O    \n",
            "kingship.      : B-per\n",
            "Germanic       : B-geo\n",
            "kingship       : B-per\n",
            "is             : O    \n",
            "cognate        : B-per\n",
            "with           : O    \n",
            "Indo-European  : B-per\n",
            "traditions     : O    \n",
            "of             : O    \n",
            "tribal         : O    \n",
            "rulership      : B-per\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy_TH2fY5uyG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}