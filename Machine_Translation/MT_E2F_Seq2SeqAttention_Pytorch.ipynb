{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MT_E2F_Seq2SeqAttention_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PWNruoSYrW8"
      },
      "source": [
        "## *Machine Translation English2French Seq2SeqAttention Pytorch*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzwmYrMJItPu"
      },
      "source": [
        "# Import libraries and Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrNftJoVIvIy",
        "outputId": "7af7c8d0-20c5-4d01-a93d-9a75c46cbc47"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/DATA/Machine_Translation_Dataset/MT_E2F_Seq2SeqAttention_Pytorch\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "MT_Seq2SeqAttention.pth.tar  small_vocab_en.csv  test.csv\n",
            "runs\t\t\t     small_vocab_fr.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oTKHiL7I_sp",
        "outputId": "a156772e-dfb6-404b-accb-17d67b6939a6"
      },
      "source": [
        "!pip install torchtext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.5.30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgibQAewI_zH"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy.data  import Field, BucketIterator, TabularDataset\n",
        "import numpy as np\n",
        "import spacy\n",
        "import random\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMGg6TCKKI-y",
        "outputId": "8b7c9c69-98a7-4cb9-f100-121f13ac7528"
      },
      "source": [
        "# load the data\n",
        "df_english = pd.read_csv('small_vocab_en.csv', sep = '/t', names = ['english'])\n",
        "df_french = pd.read_csv('small_vocab_fr.csv', sep = '/t', names = ['french'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "oYu0piT3KJB3",
        "outputId": "5e37c937-c8dc-4251-f938-957ff8ba8dea"
      },
      "source": [
        "df_english.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new jersey is sometimes quiet during autumn , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the united states is usually chilly during jul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>california is usually quiet during march , and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the united states is sometimes mild during jun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>your least liked fruit is the grape , but my l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             english\n",
              "0  new jersey is sometimes quiet during autumn , ...\n",
              "1  the united states is usually chilly during jul...\n",
              "2  california is usually quiet during march , and...\n",
              "3  the united states is sometimes mild during jun...\n",
              "4  your least liked fruit is the grape , but my l..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1FEggqIaO5Ml",
        "outputId": "fec88539-9b76-432d-f85c-3d3e2f2e9bc6"
      },
      "source": [
        "df_french.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>french</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new jersey est parfois calme pendant l' automn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>les états-unis est généralement froid en juill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>california est généralement calme en mars , et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>les états-unis est parfois légère en juin , et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>votre moins aimé fruit est le raisin , mais mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              french\n",
              "0  new jersey est parfois calme pendant l' automn...\n",
              "1  les états-unis est généralement froid en juill...\n",
              "2  california est généralement calme en mars , et...\n",
              "3  les états-unis est parfois légère en juin , et...\n",
              "4  votre moins aimé fruit est le raisin , mais mo..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwhIjtipO8On"
      },
      "source": [
        "df = pd.concat([df_english, df_french], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Onk61NQ6O_HH",
        "outputId": "a58df52a-60da-4960-f121-ab95f98dc030"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>french</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new jersey is sometimes quiet during autumn , ...</td>\n",
              "      <td>new jersey est parfois calme pendant l' automn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the united states is usually chilly during jul...</td>\n",
              "      <td>les états-unis est généralement froid en juill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>california is usually quiet during march , and...</td>\n",
              "      <td>california est généralement calme en mars , et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the united states is sometimes mild during jun...</td>\n",
              "      <td>les états-unis est parfois légère en juin , et...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>your least liked fruit is the grape , but my l...</td>\n",
              "      <td>votre moins aimé fruit est le raisin , mais mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             english                                             french\n",
              "0  new jersey is sometimes quiet during autumn , ...  new jersey est parfois calme pendant l' automn...\n",
              "1  the united states is usually chilly during jul...  les états-unis est généralement froid en juill...\n",
              "2  california is usually quiet during march , and...  california est généralement calme en mars , et...\n",
              "3  the united states is sometimes mild during jun...  les états-unis est parfois légère en juin , et...\n",
              "4  your least liked fruit is the grape , but my l...  votre moins aimé fruit est le raisin , mais mo..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC7ixXUFPCLo",
        "outputId": "8c8bcaff-2a79-47a5-c20f-213dfa8ed521"
      },
      "source": [
        "print(\"Total English Records = {}\".format(len(df['english'])))\n",
        "print(\"Total French Records = {}\".format(len(df['french'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total English Records = 137860\n",
            "Total French Records = 137860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrUo7apPPD5G"
      },
      "source": [
        "# Text Cleaning & Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AfNXipSy2E-",
        "outputId": "f6b3addb-b7e2-43f7-aaf5-5c6bc58a34bf"
      },
      "source": [
        "import string\n",
        "import re\n",
        "import os\n",
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "#from nltk.corpus import stopwords\n",
        "#stopwords_english = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA0mTGOey2IE"
      },
      "source": [
        "def process_text(text):\n",
        "    '''\n",
        "    Input: \n",
        "        text: a string containing a text\n",
        "    Output:\n",
        "        text_clean: a list of words containing the processed text\n",
        "    \n",
        "    '''\n",
        "    # remove number \n",
        "    text = re.sub('[0-9]', '', text)\n",
        "    # remove stock market tickers like $GE\n",
        "    text = re.sub(r'\\$\\w*', '', text)\n",
        "    # remove old style text \"RT\"\n",
        "    text = re.sub(r'^RT[\\s]+', '', text)\n",
        "    # remove hyperlinks\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
        "    text = re.sub(r'#', '', text)\n",
        "    # remove the dates like Mar 30 2013\n",
        "    text = re.sub('(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s\\d{2}\\s\\d{4}', ' ', text)\n",
        "    text = re.sub(r\"[/(){}\\[\\]\\|,;.:\\?\\-\\'\\\"$^]\", '', text)\n",
        " \n",
        "    #text = \" \".join(word for word in text.split() if word not in stopwords_english)\n",
        "        \n",
        "\n",
        "    return  text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F68ctG8xUqWW"
      },
      "source": [
        "df['eng'] = df['english'].apply(str).apply(process_text)\n",
        "df['fr'] = df['french'].apply(str).apply(process_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JrRf181Uw_I"
      },
      "source": [
        "df = df.drop(['english','french'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "B8B0Rny6QJ_P",
        "outputId": "9004a979-33ed-4da6-c94f-75d413d7e1b1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new jersey is sometimes quiet during autumn  a...</td>\n",
              "      <td>new jersey est parfois calme pendant l automne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the united states is usually chilly during jul...</td>\n",
              "      <td>les étatsunis est généralement froid en juille...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>california is usually quiet during march  and ...</td>\n",
              "      <td>california est généralement calme en mars  et ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the united states is sometimes mild during jun...</td>\n",
              "      <td>les étatsunis est parfois légère en juin  et i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>your least liked fruit is the grape  but my le...</td>\n",
              "      <td>votre moins aimé fruit est le raisin  mais mon...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 eng                                                 fr\n",
              "0  new jersey is sometimes quiet during autumn  a...  new jersey est parfois calme pendant l automne...\n",
              "1  the united states is usually chilly during jul...  les étatsunis est généralement froid en juille...\n",
              "2  california is usually quiet during march  and ...  california est généralement calme en mars  et ...\n",
              "3  the united states is sometimes mild during jun...  les étatsunis est parfois légère en juin  et i...\n",
              "4  your least liked fruit is the grape  but my le...  votre moins aimé fruit est le raisin  mais mon..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAUt-7tgSbkb",
        "outputId": "a39ec021-1a82-4d7b-b5bb-3a146620afd7"
      },
      "source": [
        "!python -m spacy download fr\n",
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fr_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7 MB 12.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (57.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
            "Building wheels for collected packages: fr-core-news-sm\n",
            "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-py3-none-any.whl size=14727026 sha256=6b2022bfdf0a1ed519290bd7357e85bc6b0ef2f5239ea2666636296a9975ffd6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-v9d3fid8/wheels/c9/a6/ea/0778337c34660027ee67ef3a91fb9d3600b76777a912ea1c24\n",
            "Successfully built fr-core-news-sm\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/fr_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/fr\n",
            "You can now load the model via spacy.load('fr')\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 13.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.2.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BaoXc6hBugN"
      },
      "source": [
        "spacy_eng = spacy.load(\"en\")\n",
        "spacy_fr = spacy.load(\"fr\")\n",
        "\n",
        "\n",
        "def tokenize_eng(text):\n",
        "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
        "\n",
        "\n",
        "def tokenize_fr(text):\n",
        "    return [tok.text for tok in spacy_fr.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcbp02c5BvGe"
      },
      "source": [
        "french = Field(tokenize=tokenize_fr, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "\n",
        "english = Field(tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "fields = {(\"eng\", english), (\"fr\", french)}\n",
        "\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m3XfntbUGBn"
      },
      "source": [
        "# create train and test set\n",
        "train, test = train_test_split(df, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jYVW2ALBvMm"
      },
      "source": [
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "\n",
        "train_data, test_data = TabularDataset.splits( path=\"\", train=\"train.csv\", test=\"test.csv\", format=\"csv\", fields=fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxdh8qukBvPV"
      },
      "source": [
        "english.build_vocab(train_data.eng)\n",
        "french.build_vocab(train_data.fr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzMsgXUjzSSC",
        "outputId": "a00bae19-9fdc-4e7e-d426-ead2da5c627b"
      },
      "source": [
        "len(french.vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "205"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU_4KH27zqcM",
        "outputId": "d6ba5f01-ef9c-4eca-bb5d-98943971cc34"
      },
      "source": [
        "len(english.vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS2wlhbrBvSQ"
      },
      "source": [
        "train_iterator, test_iterator = BucketIterator.splits((train_data, test_data), batch_size=32, device=\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM6MQlbl0MbP"
      },
      "source": [
        "# Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mcUi2sC0t8e"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True)\n",
        "\n",
        "        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.dropout = nn.Dropout(p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (seq_length, N) where N is batch size\n",
        "\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding shape: (seq_length, N, embedding_size)\n",
        "\n",
        "        encoder_states, (hidden, cell) = self.rnn(embedding)\n",
        "        # outputs shape: (seq_length, N, hidden_size)\n",
        "\n",
        "        # Use forward, backward cells and hidden through a linear layer\n",
        "        # so that it can be input to the decoder which is not bidirectional\n",
        "        # Also using index slicing ([idx:idx+1]) to keep the dimension\n",
        "        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
        "        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
        "\n",
        "        return encoder_states, hidden, cell\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(hidden_size * 2 + embedding_size, hidden_size, num_layers)\n",
        "\n",
        "        self.energy = nn.Linear(hidden_size * 3, 1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.softmax = nn.Softmax(dim=0)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, encoder_states, hidden, cell):\n",
        "        x = x.unsqueeze(0)\n",
        "        # x: (1, N) where N is the batch size\n",
        "\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding shape: (1, N, embedding_size)\n",
        "\n",
        "        sequence_length = encoder_states.shape[0]\n",
        "        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
        "        # h_reshaped: (seq_length, N, hidden_size*2)\n",
        "\n",
        "        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
        "        # energy: (seq_length, N, 1)\n",
        "\n",
        "        attention = self.softmax(energy)\n",
        "        # attention: (seq_length, N, 1)\n",
        "\n",
        "        # attention: (seq_length, N, 1), snk\n",
        "        # encoder_states: (seq_length, N, hidden_size*2), snl\n",
        "        # we want context_vector: (1, N, hidden_size*2), i.e knl\n",
        "        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_states)\n",
        "\n",
        "        rnn_input = torch.cat((context_vector, embedding), dim=2)\n",
        "        # rnn_input: (1, N, hidden_size*2 + embedding_size)\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
        "        # outputs shape: (1, N, hidden_size)\n",
        "\n",
        "        predictions = self.fc(outputs).squeeze(0)\n",
        "        # predictions: (N, hidden_size)\n",
        "\n",
        "        return predictions, hidden, cell\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
        "        batch_size = source.shape[1]\n",
        "        target_len = target.shape[0]\n",
        "        target_vocab_size = len(french.vocab)\n",
        "\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "        encoder_states, hidden, cell = self.encoder(source)\n",
        "\n",
        "        # First input will be <SOS> token\n",
        "        x = target[0]\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            # At every time step use encoder_states and update hidden, cell\n",
        "            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
        "\n",
        "            # Store prediction for current time step\n",
        "            outputs[t] = output\n",
        "\n",
        "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
        "            best_guess = output.argmax(1)\n",
        "\n",
        "            # With probability of teacher_force_ratio we take the actual next word\n",
        "            # otherwise we take the word that the Decoder predicted it to be.\n",
        "            # Teacher Forcing is used so that the model gets used to seeing\n",
        "            # similar inputs at training and testing time, if teacher forcing is 1\n",
        "            # then inputs at test time might be completely different than what the\n",
        "            # network is used to. This was a long comment.\n",
        "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRhKEd9HQjW2"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCApPJiWvv-R"
      },
      "source": [
        "def save_checkpoint(state, filename=\"MT_Seq2SeqAttention.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDblZEeQqFva",
        "outputId": "69750b77-58c0-42ea-dbfb-45092fdd6ff8"
      },
      "source": [
        "### We're ready to define everything we need for training our Seq2Seq model ###\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training hyperparameters\n",
        "num_epochs = 50\n",
        "learning_rate = 3e-4\n",
        "batch_size = 32\n",
        "\n",
        "# Model hyperparameters\n",
        "input_size_encoder = len(english.vocab)\n",
        "input_size_decoder = len(french.vocab)\n",
        "output_size = len(french.vocab)\n",
        "encoder_embedding_size = 300\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 1024\n",
        "num_layers = 1\n",
        "enc_dropout = 0.0\n",
        "dec_dropout = 0.0\n",
        "\n",
        "# Tensorboard to get nice loss plot\n",
        "writer = SummaryWriter(f\"runs/loss_plot\")\n",
        "step = 0\n",
        "\n",
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, test_data),\n",
        "    batch_size=batch_size,\n",
        "    sort_within_batch=True,\n",
        "    sort_key=lambda x: len(x.eng),\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout).to(device)\n",
        "\n",
        "decoder_net = Decoder(\n",
        "    input_size_decoder,\n",
        "    decoder_embedding_size,\n",
        "    hidden_size,\n",
        "    output_size,\n",
        "    num_layers,\n",
        "    dec_dropout,\n",
        ").to(device)\n",
        "\n",
        "\n",
        "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "pad_idx = french.vocab.stoi[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "\n",
        "def translate_sentence(model, sentence, french, english, device, max_length=50):\n",
        "    spacy_eng = spacy.load(\"en\")\n",
        "\n",
        "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
        "    if type(sentence) == str:\n",
        "        tokens = [token.text.lower() for token in spacy_eng(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\n",
        "    tokens.insert(0, english.init_token)\n",
        "    tokens.append(english.eos_token)\n",
        "\n",
        "    # Go through each german token and convert to an index\n",
        "    text_to_indices = [english.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    # Build encoder hidden, cell state\n",
        "    with torch.no_grad():\n",
        "        outputs_encoder, hiddens, cells = model.encoder(sentence_tensor)\n",
        "\n",
        "    outputs = [french.vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hiddens, cells = model.decoder(\n",
        "                previous_word, outputs_encoder, hiddens, cells\n",
        "            )\n",
        "            best_guess = output.argmax(1).item()\n",
        "\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        # Model predicts it's the end of the sentence\n",
        "        if output.argmax(1).item() == french.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translated_sentence = [french.vocab.itos[idx] for idx in outputs]\n",
        "\n",
        "    return ' '.join(ix for ix in translated_sentence[1:])\n",
        "\n",
        "Original_english_sentence = test.iloc[1]['eng']\n",
        "Original_French_word = test.iloc[1]['fr']\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "\n",
        "    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
        "    save_checkpoint(checkpoint)\n",
        "\n",
        "    if epoch%5 == 0:\n",
        "       model.eval()\n",
        "\n",
        "       translated_sentence = translate_sentence(model, Original_english_sentence, french, english, device, max_length=50)\n",
        "\n",
        "       print(f\"Original English example sentence: \\n {Original_english_sentence}\")\n",
        "       print(f\"original French translated example sentence: \\n {Original_French_word}\")\n",
        "       print(f\"Trained French  translated example sentence: \\n {translated_sentence}\")\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        # Get input and targets and get to cuda\n",
        "        inp_data = batch.eng.to(device)\n",
        "        target = batch.fr.to(device)\n",
        "\n",
        "        # Forward prop\n",
        "        output = model(inp_data, target)\n",
        "\n",
        "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
        "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
        "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
        "        # way that we have output_words * batch_size that we want to send in into\n",
        "        # our cost function, so we need to do some reshapin. While we're at it\n",
        "        # Let's also remove the start token while we're at it\n",
        "        output = output[1:].reshape(-1, output.shape[2])\n",
        "        target = target[1:].reshape(-1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Back prop\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
        "        # within a healthy range\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "        # Gradient descent step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Plot to tensorboard\n",
        "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "        step += 1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0 / 50]\n",
            "=> Saving checkpoint\n",
            "Original English example sentence: \n",
            " france is warm during august  but it is sometimes mild in february \n",
            "original French translated example sentence: \n",
            " france est chaud au mois d août  mais il est parfois doux en février \n",
            "Trained French  translated example sentence: \n",
            " his thinks fall dislike like spring mice least     and plans favorite favorite favorite tower <sos> his thinks fall dislike like spring mice least     and plans favorite favorite favorite tower <sos> his thinks fall dislike like spring mice least     and plans favorite favorite favorite tower\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsmtN_KAZkZW"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqfZgNKH0hxw"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "def bleu(data, model, english, french, device):\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    for example in data:\n",
        "        src = vars(example)['eng']\n",
        "        trg = vars(example)[\"fr\"]\n",
        "\n",
        "        prediction = translate_sentence(model, src, french, english, device)\n",
        "        \n",
        "\n",
        "        targets.append([trg])\n",
        "        outputs.append(prediction)\n",
        "\n",
        "    return bleu_score(outputs, targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh1tDmV90k9Q",
        "outputId": "1ccdd659-d25c-40b3-e0ba-ee7f6aab7046"
      },
      "source": [
        "Original_english_sentence = test.iloc[3]['eng']\n",
        "Original_French_word = test.iloc[3]['fr']\n",
        "model.eval()\n",
        "\n",
        "translated_sentence = translate_sentence(model, Original_english_sentence, french, english, device, max_length=50)\n",
        "\n",
        "print(f\"Original English example sentence: \\n {Original_english_sentence}\")\n",
        "print(f\"original French translated example sentence: \\n {Original_French_word}\")\n",
        "print(f\"Trained French  translated example sentence: \\n {translated_sentence}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original English example sentence: \n",
            " they want to go to china next july \n",
            "original French translated example sentence: \n",
            " ils veulent aller en chine en juillet prochain \n",
            "Trained French  translated example sentence: \n",
            " ils veulent aller en chine en juillet prochain <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko32547WWrWI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}