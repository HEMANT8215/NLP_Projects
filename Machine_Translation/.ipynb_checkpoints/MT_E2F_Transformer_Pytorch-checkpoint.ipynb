{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gd-knWKUYFeK"
   },
   "source": [
    "## *Machine Translation English2French Transformer Pytorch*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzwmYrMJItPu"
   },
   "source": [
    "# Import libraries and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18214,
     "status": "ok",
     "timestamp": 1624603213854,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "HrNftJoVIvIy",
    "outputId": "452ec0c1-9132-4ccd-f1b1-cea2262b1ee2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "small_vocab_en.csv  small_vocab_fr.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/DATA/Machine_Translation_Dataset/MT_E2F_Transformer_Pytorch\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7303,
     "status": "ok",
     "timestamp": 1624603221155,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "7oTKHiL7I_sp",
    "outputId": "8291bdf6-d4b8-4de5-fe04-997fcabbea47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
      "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.9.0+cu102)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.41.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.5.30)\n",
      "Collecting python-math\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/8c/60c13be29a2f2e74c0313f2e62c7f751c944fe54b917afa5f88144e71a66/python_math-0.0.1-py3-none-any.whl\n",
      "Installing collected packages: python-math\n",
      "Successfully installed python-math-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext\n",
    "!pip install python-math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5113,
     "status": "ok",
     "timestamp": 1624603226249,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "FgibQAewI_zH"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchtext.legacy.data  import Field, BucketIterator, TabularDataset\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3613,
     "status": "ok",
     "timestamp": 1624603229858,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "NMGg6TCKKI-y",
    "outputId": "61d4fcdf-6dca-410c-b2bb-f7144bc8a0ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "df_english = pd.read_csv('small_vocab_en.csv', sep = '/t', names = ['english'])\n",
    "df_french = pd.read_csv('small_vocab_fr.csv', sep = '/t', names = ['french'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1624603229859,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "oYu0piT3KJB3",
    "outputId": "25448080-59c4-43fd-9ffd-b07b9aa8bfe8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new jersey is sometimes quiet during autumn , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the united states is usually chilly during jul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>california is usually quiet during march , and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the united states is sometimes mild during jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your least liked fruit is the grape , but my l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english\n",
       "0  new jersey is sometimes quiet during autumn , ...\n",
       "1  the united states is usually chilly during jul...\n",
       "2  california is usually quiet during march , and...\n",
       "3  the united states is sometimes mild during jun...\n",
       "4  your least liked fruit is the grape , but my l..."
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_english.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1624603229860,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "1FEggqIaO5Ml",
    "outputId": "129887ba-4df2-470c-a3d6-01148d9b034a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>french</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new jersey est parfois calme pendant l' automn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>les états-unis est généralement froid en juill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>california est généralement calme en mars , et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>les états-unis est parfois légère en juin , et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>votre moins aimé fruit est le raisin , mais mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              french\n",
       "0  new jersey est parfois calme pendant l' automn...\n",
       "1  les états-unis est généralement froid en juill...\n",
       "2  california est généralement calme en mars , et...\n",
       "3  les états-unis est parfois légère en juin , et...\n",
       "4  votre moins aimé fruit est le raisin , mais mo..."
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_french.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1624603229861,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "jwhIjtipO8On"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_english, df_french], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1624603229861,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "Onk61NQ6O_HH",
    "outputId": "fb1731eb-eab2-43d7-d1e3-3431385c6dea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>french</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new jersey is sometimes quiet during autumn , ...</td>\n",
       "      <td>new jersey est parfois calme pendant l' automn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the united states is usually chilly during jul...</td>\n",
       "      <td>les états-unis est généralement froid en juill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>california is usually quiet during march , and...</td>\n",
       "      <td>california est généralement calme en mars , et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the united states is sometimes mild during jun...</td>\n",
       "      <td>les états-unis est parfois légère en juin , et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your least liked fruit is the grape , but my l...</td>\n",
       "      <td>votre moins aimé fruit est le raisin , mais mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english                                             french\n",
       "0  new jersey is sometimes quiet during autumn , ...  new jersey est parfois calme pendant l' automn...\n",
       "1  the united states is usually chilly during jul...  les états-unis est généralement froid en juill...\n",
       "2  california is usually quiet during march , and...  california est généralement calme en mars , et...\n",
       "3  the united states is sometimes mild during jun...  les états-unis est parfois légère en juin , et...\n",
       "4  your least liked fruit is the grape , but my l...  votre moins aimé fruit est le raisin , mais mo..."
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1624603229861,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "FC7ixXUFPCLo",
    "outputId": "c17a5d25-859c-4445-e9e7-37eba62c9dbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total English Records = 137860\n",
      "Total French Records = 137860\n"
     ]
    }
   ],
   "source": [
    "print(\"Total English Records = {}\".format(len(df['english'])))\n",
    "print(\"Total French Records = {}\".format(len(df['french'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrUo7apPPD5G"
   },
   "source": [
    "# Text Cleaning & Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1538,
     "status": "ok",
     "timestamp": 1624603231380,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "5AfNXipSy2E-",
    "outputId": "54ad2b98-7d16-4277-a5fb-8353d734fcb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "#from nltk.corpus import stopwords\n",
    "#stopwords_english = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624603231381,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "JA0mTGOey2IE"
   },
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    '''\n",
    "    Input: \n",
    "        text: a string containing a text\n",
    "    Output:\n",
    "        text_clean: a list of words containing the processed text\n",
    "    \n",
    "    '''\n",
    "    # remove number \n",
    "    text = re.sub('[0-9]', '', text)\n",
    "    # remove stock market tickers like $GE\n",
    "    text = re.sub(r'\\$\\w*', '', text)\n",
    "    # remove old style text \"RT\"\n",
    "    text = re.sub(r'^RT[\\s]+', '', text)\n",
    "    # remove hyperlinks\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    # remove the dates like Mar 30 2013\n",
    "    text = re.sub('(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s\\d{2}\\s\\d{4}', ' ', text)\n",
    "    text = re.sub(r\"[/(){}\\[\\]\\|,;.:\\?\\-\\'\\\"$^]\", '', text)\n",
    " \n",
    "    #text = \" \".join(word for word in text.split() if word not in stopwords_english)\n",
    "    \n",
    "   \n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "   \n",
    "     \n",
    "\n",
    "    return  text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2400,
     "status": "ok",
     "timestamp": 1624603233778,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "F68ctG8xUqWW"
   },
   "outputs": [],
   "source": [
    "df['eng'] = df['english'].apply(str).apply(process_text)\n",
    "df['fr'] = df['french'].apply(str).apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1200,
     "status": "ok",
     "timestamp": 1624603234976,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "2JrRf181Uw_I"
   },
   "outputs": [],
   "source": [
    "df = df.drop(['english','french'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1624603234977,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "B8B0Rny6QJ_P",
    "outputId": "8297b00d-f868-4595-866e-98d10d82d6ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new jersey is sometimes quiet during autumn  a...</td>\n",
       "      <td>new jersey est parfois calme pendant l automne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the united states is usually chilly during jul...</td>\n",
       "      <td>les étatsunis est généralement froid en juille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>california is usually quiet during march  and ...</td>\n",
       "      <td>california est généralement calme en mars  et ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the united states is sometimes mild during jun...</td>\n",
       "      <td>les étatsunis est parfois légère en juin  et i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your least liked fruit is the grape  but my le...</td>\n",
       "      <td>votre moins aimé fruit est le raisin  mais mon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 eng                                                 fr\n",
       "0  new jersey is sometimes quiet during autumn  a...  new jersey est parfois calme pendant l automne...\n",
       "1  the united states is usually chilly during jul...  les étatsunis est généralement froid en juille...\n",
       "2  california is usually quiet during march  and ...  california est généralement calme en mars  et ...\n",
       "3  the united states is sometimes mild during jun...  les étatsunis est parfois légère en juin  et i...\n",
       "4  your least liked fruit is the grape  but my le...  votre moins aimé fruit est le raisin  mais mon..."
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12583,
     "status": "ok",
     "timestamp": 1624603247550,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "bAUt-7tgSbkb",
    "outputId": "2c237946-7d7f-4b96-c70e-d69994f55b79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr_core_news_sm==2.2.5\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7MB)\n",
      "\u001b[K     |████████████████████████████████| 14.7MB 10.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.19.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.8.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (57.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.7.4.3)\n",
      "Building wheels for collected packages: fr-core-news-sm\n",
      "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-cp37-none-any.whl size=14727024 sha256=3660d4cd4d01542274a0122acaed8fed17883f9a0959dd26802a2850b59b3695\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-hhhg9159/wheels/46/1b/e6/29b020e3f9420a24c3f463343afe5136aaaf955dbc9e46dfc5\n",
      "Successfully built fr-core-news-sm\n",
      "Installing collected packages: fr-core-news-sm\n",
      "Successfully installed fr-core-news-sm-2.2.5\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/fr_core_news_sm -->\n",
      "/usr/local/lib/python3.7/dist-packages/spacy/data/fr\n",
      "You can now load the model via spacy.load('fr')\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
      "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 9261,
     "status": "ok",
     "timestamp": 1624603256795,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "_BaoXc6hBugN"
   },
   "outputs": [],
   "source": [
    "spacy_eng = spacy.load(\"en\")\n",
    "spacy_fr = spacy.load(\"fr\")\n",
    "\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "\n",
    "def tokenize_fr(text):\n",
    "    return [tok.text for tok in spacy_fr.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1624603256796,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "hcbp02c5BvGe"
   },
   "outputs": [],
   "source": [
    "french = Field(tokenize=tokenize_fr, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "english = Field(tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "fields = {(\"eng\", english), (\"fr\", french)}\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1624603256796,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "5m3XfntbUGBn"
   },
   "outputs": [],
   "source": [
    "# create train and test set\n",
    "train, test = train_test_split(df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1624603256797,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "Blue2j0ZUIb_",
    "outputId": "0529af12-8df3-48fd-a248-b3134a71eca2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94354    the united states is pleasant during july  and...\n",
       "Name: eng, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['eng'][1:2].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 16898,
     "status": "ok",
     "timestamp": 1624603273677,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "2jYVW2ALBvMm"
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "train_data, test_data = TabularDataset.splits( path=\"\", train=\"train.csv\", test=\"test.csv\", format=\"csv\", fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 917,
     "status": "ok",
     "timestamp": 1624603274586,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "Zxdh8qukBvPV"
   },
   "outputs": [],
   "source": [
    "english.build_vocab(train_data.eng)\n",
    "french.build_vocab(train_data.fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1624603274586,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "JzMsgXUjzSSC",
    "outputId": "5b8f991a-4fed-48a7-b355-5a816167f106"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(french.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1624603274586,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "aU_4KH27zqcM",
    "outputId": "89f41bb8-0a1d-41e0-fe96-534a86b7fd43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624603274586,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "eS2wlhbrBvSQ"
   },
   "outputs": [],
   "source": [
    "train_iterator, test_iterator = BucketIterator.splits((train_data, test_data), batch_size=32, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EM6MQlbl0MbP"
   },
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624603274586,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "dUszZOzyx6cw"
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_len,\n",
    "        device,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
    "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "\n",
    "        self.device = device\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
    "\n",
    "        # (N, src_len)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_seq_length, N = src.shape\n",
    "        trg_seq_length, N = trg.shape\n",
    "\n",
    "#adding zeros is an easy way\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length)\n",
    "            .reshape(src_seq_length,1)  + torch.zeros(src_seq_length,N) \n",
    "        ).to(device)\n",
    "        \n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length)\n",
    "            .reshape(trg_seq_length,1)  + torch.zeros(trg_seq_length,N) \n",
    "        ).to(device)\n",
    "\n",
    "\n",
    "\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length)\n",
    "            .unsqueeze(1)\n",
    "            .expand(src_seq_length, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length)\n",
    "            .unsqueeze(1)\n",
    "            .expand(trg_seq_length, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        embed_src = self.dropout(\n",
    "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
    "        )\n",
    "        embed_trg = self.dropout(\n",
    "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
    "        )\n",
    "\n",
    "        src_padding_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        out = self.transformer(\n",
    "            embed_src,\n",
    "            embed_trg,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_mask=trg_mask,\n",
    "        )\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRhKEd9HQjW2"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624603274587,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "G3ETZiX6RYDv"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"MT_Transformer.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 8836,
     "status": "ok",
     "timestamp": 1624603283420,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "HZDCgIYzKPg-"
   },
   "outputs": [],
   "source": [
    "# We're ready to define everything we need for training our Seq2Seq model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 20\n",
    "learning_rate = 3e-4\n",
    "batch_size = 32\n",
    "\n",
    "# Model hyperparameters\n",
    "src_vocab_size = len(english.vocab)\n",
    "trg_vocab_size = len(french.vocab)\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dropout = 0.10\n",
    "max_len = 50\n",
    "forward_expansion = 4\n",
    "src_pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "\n",
    "# Tensorboard to get nice loss plot\n",
    "writer = SummaryWriter(\"runs/loss_plot\")\n",
    "step = 0\n",
    "\n",
    "\n",
    "model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = french.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1624603283420,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "yNL0oJb4zoNn"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, english, french, device, max_length=50):\n",
    "   \n",
    "    spacy_eng = spacy.load(\"en\")\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    if type(sentence) == str:\n",
    "        tokens = [token.text.lower() for token in spacy_eng(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, english.init_token)\n",
    "    tokens.append(english.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [english.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    outputs = [french.vocab.stoi[\"<sos>\"]]\n",
    "    for i in range(max_length):\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, trg_tensor)\n",
    "\n",
    "        best_guess = output.argmax(2)[-1, :].item()\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        if best_guess == french.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [french.vocab.itos[idx] for idx in outputs]\n",
    "    # remove start token\n",
    "    return ' '.join(ix for ix in translated_sentence[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1624603283421,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "7Z_v0VS40NoO"
   },
   "outputs": [],
   "source": [
    "Original_english_sentence = test.iloc[3]['eng']\n",
    "Original_French_word = test.iloc[3]['fr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2653014,
     "status": "ok",
     "timestamp": 1624605936414,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "XsFe4VyeRcN4",
    "outputId": "d7518001-e38c-448b-f16d-fd8d4d585a96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 20]\n",
      "=> Saving checkpoint\n",
      "Original English example sentence: \n",
      " she dislikes peaches  oranges  and lemons \n",
      "original French translated example sentence: \n",
      " elle déteste les pêches  les oranges  les citrons et les \n",
      "Trained French  translated example sentence: \n",
      " que lapins pommes petit dans    dernière aller aller aller aller aller dans       lapins animal mais aller aller aller français juin lapins pommes lapins dans petit animal mais aller aller bleu    singe dans lapins étaient aller aller bleu singe petit étaient bleu mais aller visite aimentils mais\n",
      "train crossentropy at epoch 0 loss:  0.13965346891281222\n",
      "[Epoch 1 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 1 loss:  0.055853391360383926\n",
      "[Epoch 2 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 2 loss:  0.051899451493703945\n",
      "[Epoch 3 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 3 loss:  0.05086200933158013\n",
      "[Epoch 4 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 4 loss:  0.049960382380837394\n",
      "[Epoch 5 / 20]\n",
      "=> Saving checkpoint\n",
      "Original English example sentence: \n",
      " she dislikes peaches  oranges  and lemons \n",
      "original French translated example sentence: \n",
      " elle déteste les pêches  les oranges  les citrons et les \n",
      "Trained French  translated example sentence: \n",
      " elle déteste les pêches   les oranges   les citrons et les <eos>\n",
      "train crossentropy at epoch 5 loss:  0.04734216787676553\n",
      "[Epoch 6 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 6 loss:  0.0455402893446772\n",
      "[Epoch 7 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 7 loss:  0.044408093007255484\n",
      "[Epoch 8 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 8 loss:  0.04419275030122456\n",
      "[Epoch 9 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 9 loss:  0.04245649756373316\n",
      "[Epoch 10 / 20]\n",
      "=> Saving checkpoint\n",
      "Original English example sentence: \n",
      " she dislikes peaches  oranges  and lemons \n",
      "original French translated example sentence: \n",
      " elle déteste les pêches  les oranges  les citrons et les \n",
      "Trained French  translated example sentence: \n",
      " elle déteste les pêches   les oranges   les citrons et les <eos>\n",
      "train crossentropy at epoch 10 loss:  0.04141998137148071\n",
      "[Epoch 11 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 11 loss:  0.04080981609186752\n",
      "[Epoch 12 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 12 loss:  0.039289491767805336\n",
      "[Epoch 13 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 13 loss:  0.03831420171140852\n",
      "[Epoch 14 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 14 loss:  0.03713643652602623\n",
      "[Epoch 15 / 20]\n",
      "=> Saving checkpoint\n",
      "Original English example sentence: \n",
      " she dislikes peaches  oranges  and lemons \n",
      "original French translated example sentence: \n",
      " elle déteste les pêches  les oranges  les citrons et les \n",
      "Trained French  translated example sentence: \n",
      " elle déteste les pêches   les oranges et les citrons <eos>\n",
      "train crossentropy at epoch 15 loss:  0.03656078482614931\n",
      "[Epoch 16 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 16 loss:  0.03619437263399562\n",
      "[Epoch 17 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 17 loss:  0.03469379071419787\n",
      "[Epoch 18 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 18 loss:  0.03407099992684038\n",
      "[Epoch 19 / 20]\n",
      "=> Saving checkpoint\n",
      "train crossentropy at epoch 19 loss:  0.033371589553737924\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "    stepLoss=[]\n",
    "    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "    save_checkpoint(checkpoint)\n",
    "    \n",
    "    if epoch%5 == 0:\n",
    "       model.eval()\n",
    "\n",
    "       translated_sentence = translate_sentence(model, Original_english_sentence, english, french, device, max_length=50)\n",
    "\n",
    "       print(f\"Original English example sentence: \\n {Original_english_sentence}\")\n",
    "       print(f\"original French translated example sentence: \\n {Original_French_word}\")\n",
    "       print(f\"Trained French  translated example sentence: \\n {translated_sentence}\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = batch.eng.to(device)\n",
    "        target = batch.fr.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target[:-1, :])\n",
    "\n",
    "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have output_words * batch_size that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin.\n",
    "        # Let's also remove the start token while we're at it\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # plot to tensorboard\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "\n",
    "    mean_loss = sum(losses) / len(losses)\n",
    "\n",
    "    print(\"train crossentropy at epoch {} loss: \".format(epoch), mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsmtN_KAZkZW"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1624605937126,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "YrJRkGKPRn8G",
    "outputId": "70b46225-0ec2-4eb3-d96a-ca708bef5bea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "load_checkpoint(torch.load(\"MT_Transformer.pth.tar\"), model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 892,
     "status": "ok",
     "timestamp": 1624605938000,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "Yh1tDmV90k9Q",
    "outputId": "f5ba61ab-a658-4145-b8d3-7d7da375e38b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original English example sentence: \n",
      " she dislikes peaches  oranges  and lemons \n",
      "original French translated example sentence: \n",
      " elle déteste les pêches  les oranges  les citrons et les \n",
      "Trained French  translated example sentence: \n",
      " elle déteste les pêches   les oranges et les citrons <eos>\n"
     ]
    }
   ],
   "source": [
    "Original_english_sentence = test.iloc[3]['eng']\n",
    "Original_French_word = test.iloc[3]['fr']\n",
    "model.eval()\n",
    "\n",
    "translated_sentence = translate_sentence(model, Original_english_sentence, english, french, device, max_length=50)\n",
    "\n",
    "print(f\"Original English example sentence: \\n {Original_english_sentence}\")\n",
    "print(f\"original French translated example sentence: \\n {Original_French_word}\")\n",
    "print(f\"Trained French  translated example sentence: \\n {translated_sentence}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOIDyH1GjdIgrL0PeFADqaX",
   "collapsed_sections": [],
   "name": "MT_E2F_Transformer_Pytorch.ipynb",
   "provenance": [
    {
     "file_id": "1RkbyF8nZ0sHB7GWKwQB_P5Os6nPveGY2",
     "timestamp": 1623906547904
    },
    {
     "file_id": "16l8WSq6GVK2Ksp2Nr7QsjHtuY9n9xG8U",
     "timestamp": 1623825651074
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
