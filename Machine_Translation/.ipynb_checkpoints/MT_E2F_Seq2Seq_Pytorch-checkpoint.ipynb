{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9eEjHPoY2fx"
   },
   "source": [
    "## *Machine Translation English2French Seq2Seq Pytorch*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzwmYrMJItPu"
   },
   "source": [
    "# Import libraries and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18331,
     "status": "ok",
     "timestamp": 1624026757200,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "HrNftJoVIvIy",
    "outputId": "03ea77e2-120f-48e7-f435-43f614d5325f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "small_vocab_en.csv  small_vocab_fr.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/DATA/Machine_Translation_Dataset/MT_E2F_Seq2Seq_Pytorch\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4313,
     "status": "ok",
     "timestamp": 1624026766313,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "7oTKHiL7I_sp",
    "outputId": "9a49797b-cea3-40d5-adb3-7956f138f267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Using cached torchtext-0.10.0-cp39-cp39-macosx_11_0_arm64.whl (1.6 MB)\n",
      "Collecting torch\n",
      "  Using cached torch-1.9.0-cp39-none-macosx_11_0_arm64.whl (41.5 MB)\n",
      "Requirement already satisfied: requests in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torchtext) (2.25.1)\n",
      "Requirement already satisfied: numpy in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torchtext) (1.19.5)\n",
      "Requirement already satisfied: tqdm in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torchtext) (4.61.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests->torchtext) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests->torchtext) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests->torchtext) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests->torchtext) (2.10)\n",
      "Requirement already satisfied: typing-extensions in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torch->torchtext) (3.7.4.3)\n",
      "Installing collected packages: torch, torchtext\n",
      "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.1.1-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.5-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.5-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.7\n",
      "  Using cached spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: setuptools in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from spacy) (49.6.0.post20210108)\n",
      "Collecting catalogue<2.1.0,>=2.0.4\n",
      "  Using cached catalogue-2.0.4-py3-none-any.whl (16 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Using cached blis-0.7.4-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Using cached srsly-2.4.1-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from spacy) (2.25.1)\n",
      "Collecting pathy>=0.3.5\n",
      "  Using cached pathy-0.6.0-py3-none-any.whl (42 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Using cached pydantic-1.8.2-py3-none-any.whl (126 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.5-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Using cached wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Using cached typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied: jinja2 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from spacy) (3.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from spacy) (4.61.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from spacy) (21.0)\n",
      "Collecting thinc<8.1.0,>=8.0.8\n",
      "  Using cached thinc-8.0.8-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Using cached smart_open-5.1.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Collecting click<7.2.0,>=7.1.1\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: murmurhash, cymem, click, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, blis, thinc, spacy-legacy, pathy, spacy\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.1\n",
      "    Uninstalling click-8.0.1:\n",
      "      Successfully uninstalled click-8.0.1\n",
      "Successfully installed blis-0.7.4 catalogue-2.0.4 click-7.1.2 cymem-2.0.5 murmurhash-1.0.5 pathy-0.6.0 preshed-3.0.5 pydantic-1.8.2 smart-open-5.1.0 spacy-3.1.1 spacy-legacy-3.0.8 srsly-2.4.1 thinc-8.0.8 typer-0.3.2 wasabi-0.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5077,
     "status": "ok",
     "timestamp": 1624026771382,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "FgibQAewI_zH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.legacy.data  import Field, BucketIterator, TabularDataset\n",
    "import numpy as np\n",
    "#import spacy\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2052,
     "status": "ok",
     "timestamp": 1624026773413,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "NMGg6TCKKI-y",
    "outputId": "0548d7c2-6e35-4021-8967-1cd283f91af4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "df_english = pd.read_csv('small_vocab_en.csv', sep = '/t', names = ['english'])\n",
    "df_french = pd.read_csv('small_vocab_fr.csv', sep = '/t', names = ['french'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1624026773414,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "oYu0piT3KJB3",
    "outputId": "2a2674b8-7044-4e61-b4f5-d5e3b31b9227"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new jersey is sometimes quiet during autumn , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the united states is usually chilly during jul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>california is usually quiet during march , and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the united states is sometimes mild during jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your least liked fruit is the grape , but my l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english\n",
       "0  new jersey is sometimes quiet during autumn , ...\n",
       "1  the united states is usually chilly during jul...\n",
       "2  california is usually quiet during march , and...\n",
       "3  the united states is sometimes mild during jun...\n",
       "4  your least liked fruit is the grape , but my l..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_english.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1624026773414,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "1FEggqIaO5Ml",
    "outputId": "38e9f1d5-5415-4753-e8c8-811297a49b39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>french</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new jersey est parfois calme pendant l' automn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>les états-unis est généralement froid en juill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>california est généralement calme en mars , et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>les états-unis est parfois légère en juin , et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>votre moins aimé fruit est le raisin , mais mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              french\n",
       "0  new jersey est parfois calme pendant l' automn...\n",
       "1  les états-unis est généralement froid en juill...\n",
       "2  california est généralement calme en mars , et...\n",
       "3  les états-unis est parfois légère en juin , et...\n",
       "4  votre moins aimé fruit est le raisin , mais mo..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_french.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1624026773414,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "jwhIjtipO8On"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_english, df_french], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1624026773415,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "Onk61NQ6O_HH",
    "outputId": "546fae45-d601-4819-bb7d-b5d6def764ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>french</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new jersey is sometimes quiet during autumn , ...</td>\n",
       "      <td>new jersey est parfois calme pendant l' automn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the united states is usually chilly during jul...</td>\n",
       "      <td>les états-unis est généralement froid en juill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>california is usually quiet during march , and...</td>\n",
       "      <td>california est généralement calme en mars , et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the united states is sometimes mild during jun...</td>\n",
       "      <td>les états-unis est parfois légère en juin , et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your least liked fruit is the grape , but my l...</td>\n",
       "      <td>votre moins aimé fruit est le raisin , mais mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0  new jersey is sometimes quiet during autumn , ...   \n",
       "1  the united states is usually chilly during jul...   \n",
       "2  california is usually quiet during march , and...   \n",
       "3  the united states is sometimes mild during jun...   \n",
       "4  your least liked fruit is the grape , but my l...   \n",
       "\n",
       "                                              french  \n",
       "0  new jersey est parfois calme pendant l' automn...  \n",
       "1  les états-unis est généralement froid en juill...  \n",
       "2  california est généralement calme en mars , et...  \n",
       "3  les états-unis est parfois légère en juin , et...  \n",
       "4  votre moins aimé fruit est le raisin , mais mo...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1624026773415,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "FC7ixXUFPCLo",
    "outputId": "3aa09179-5582-4b43-b33f-7b9e363cd959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total English Records = 137860\n",
      "Total French Records = 137860\n"
     ]
    }
   ],
   "source": [
    "print(\"Total English Records = {}\".format(len(df['english'])))\n",
    "print(\"Total French Records = {}\".format(len(df['french'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrUo7apPPD5G"
   },
   "source": [
    "# Text Cleaning & Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1291,
     "status": "ok",
     "timestamp": 1624026774698,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "NAM7GDomGqX9",
    "outputId": "6c25a1c9-1aef-496c-8968-ddc769eba78e"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1_/5jmrsdkn5zjfcj8_nmbnx2t80000gn/T/ipykernel_16033/2836807837.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#nltk.download('stopwords')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'punkt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "#from nltk.corpus import stopwords\n",
    "#stopwords_english = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1624026774699,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "zzvkinHMpYPc"
   },
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    '''\n",
    "    Input: \n",
    "        text: a string containing a text\n",
    "    Output:\n",
    "        text_clean: a list of words containing the processed text\n",
    "    \n",
    "    '''\n",
    "    # remove number \n",
    "    text = re.sub('[0-9]', '', text)\n",
    "    # remove stock market tickers like $GE\n",
    "    text = re.sub(r'\\$\\w*', '', text)\n",
    "    # remove old style text \"RT\"\n",
    "    text = re.sub(r'^RT[\\s]+', '', text)\n",
    "    # remove hyperlinks\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    # remove the dates like Mar 30 2013\n",
    "    text = re.sub('(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s\\d{2}\\s\\d{4}', ' ', text)\n",
    "    text = re.sub(r\"[/(){}\\[\\]\\|,;.:\\?\\-\\'\\\"$^]\", '', text)\n",
    " \n",
    "    #text = \" \".join(word for word in text.split() if word not in stopwords_english)\n",
    "     \n",
    "\n",
    "    return  text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3140,
     "status": "ok",
     "timestamp": 1624026777835,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "8nRkv9KfP3V5"
   },
   "outputs": [],
   "source": [
    "df['eng'] = df['english'].apply(str).apply(process_text)\n",
    "df['fr'] = df['french'].apply(str).apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1624026777836,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "FhunKIDKCgPN"
   },
   "outputs": [],
   "source": [
    "df = df.drop(['english','french'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1624026777836,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "B8B0Rny6QJ_P",
    "outputId": "2e274b6d-5976-4fa1-a832-20dc862895c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new jersey is sometimes quiet during autumn  a...</td>\n",
       "      <td>new jersey est parfois calme pendant l automne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the united states is usually chilly during jul...</td>\n",
       "      <td>les étatsunis est généralement froid en juille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>california is usually quiet during march  and ...</td>\n",
       "      <td>california est généralement calme en mars  et ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the united states is sometimes mild during jun...</td>\n",
       "      <td>les étatsunis est parfois légère en juin  et i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your least liked fruit is the grape  but my le...</td>\n",
       "      <td>votre moins aimé fruit est le raisin  mais mon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 eng  \\\n",
       "0  new jersey is sometimes quiet during autumn  a...   \n",
       "1  the united states is usually chilly during jul...   \n",
       "2  california is usually quiet during march  and ...   \n",
       "3  the united states is sometimes mild during jun...   \n",
       "4  your least liked fruit is the grape  but my le...   \n",
       "\n",
       "                                                  fr  \n",
       "0  new jersey est parfois calme pendant l automne...  \n",
       "1  les étatsunis est généralement froid en juille...  \n",
       "2  california est généralement calme en mars  et ...  \n",
       "3  les étatsunis est parfois légère en juin  et i...  \n",
       "4  votre moins aimé fruit est le raisin  mais mon...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13778,
     "status": "ok",
     "timestamp": 1624026791597,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "bAUt-7tgSbkb",
    "outputId": "1cb4ac21-ec16-44f8-c0ce-4cf073989073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr_core_news_sm==2.2.5\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7MB)\n",
      "\u001b[K     |████████████████████████████████| 14.7MB 8.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.19.5)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (57.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.8.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.5.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.4.1)\n",
      "Building wheels for collected packages: fr-core-news-sm\n",
      "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-cp37-none-any.whl size=14727024 sha256=88e754e0d06a7925033ad40894e5859fe4485c098f0bed9c9fa703520d91fbd7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sxh9pdvp/wheels/46/1b/e6/29b020e3f9420a24c3f463343afe5136aaaf955dbc9e46dfc5\n",
      "Successfully built fr-core-news-sm\n",
      "Installing collected packages: fr-core-news-sm\n",
      "Successfully installed fr-core-news-sm-2.2.5\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('fr_core_news_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/fr_core_news_sm -->\n",
      "/usr/local/lib/python3.7/dist-packages/spacy/data/fr\n",
      "You can now load the model via spacy.load('fr')\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.5.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
      "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 9544,
     "status": "ok",
     "timestamp": 1624026801133,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "_BaoXc6hBugN"
   },
   "outputs": [],
   "source": [
    "spacy_eng = spacy.load(\"en\")\n",
    "spacy_fr = spacy.load(\"fr\")\n",
    "\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "\n",
    "def tokenize_fr(text):\n",
    "    return [tok.text for tok in spacy_fr.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1624026801133,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "BTD7ayabAKQK",
    "outputId": "5bd2fcc0-3866-407c-f6a3-905456115b02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7fd5bef66950>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1624026801133,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "MRKwQzKXA2Sb",
    "outputId": "0fbd6e71-6405-48e2-97f6-3759e22425dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.fr.French at 0x7fd5be015bd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1624026801133,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "hcbp02c5BvGe"
   },
   "outputs": [],
   "source": [
    "french = Field(tokenize=tokenize_fr, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "english = Field(tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "fields = {\"eng\": (\"eng\", english), \"fr\": (\"fr\", french)}         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 16870,
     "status": "ok",
     "timestamp": 1624026817994,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "2jYVW2ALBvMm"
   },
   "outputs": [],
   "source": [
    "# create train and test set\n",
    "train, test = train_test_split(df, test_size=0.1)\n",
    "\n",
    "train.to_csv(\"train.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "train_data, test_data = TabularDataset.splits( path=\"\", train=\"train.csv\", test=\"test.csv\", format=\"csv\", fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1624026818553,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "l9ahTQkKAP9D"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1624026818554,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "_8k1Ta-IAfFY",
    "outputId": "c931e4c8-bbce-4fd1-fb67-420c51f0528d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>she was driving a rusty red truck</td>\n",
       "      <td>elle conduisait un camion rouge rouillé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he dislikes pears  peaches  and grapefruit</td>\n",
       "      <td>il aime pas les poires  les pêches et le pampl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>india is sometimes cold during april  and it i...</td>\n",
       "      <td>l inde est parfois froid en avril  et il est p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the lime is his most loved fruit  but the grap...</td>\n",
       "      <td>la chaux est son fruit le plus cher  mais le r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>france is never cold during winter  and it is ...</td>\n",
       "      <td>france ne fait jamais froid pendant l hiver  e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 eng                                                 fr\n",
       "0                 she was driving a rusty red truck            elle conduisait un camion rouge rouillé \n",
       "1        he dislikes pears  peaches  and grapefruit   il aime pas les poires  les pêches et le pampl...\n",
       "2  india is sometimes cold during april  and it i...  l inde est parfois froid en avril  et il est p...\n",
       "3  the lime is his most loved fruit  but the grap...  la chaux est son fruit le plus cher  mais le r...\n",
       "4  france is never cold during winter  and it is ...  france ne fait jamais froid pendant l hiver  e..."
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1624026818554,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "VBGv7-ul6eiw",
    "outputId": "1205253b-26d7-4131-d6d1-1a7f24ac1a9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.legacy.data.dataset.TabularDataset object at 0x7fd692a9b350>\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1624026819078,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "Zxdh8qukBvPV"
   },
   "outputs": [],
   "source": [
    "english.build_vocab(train_data.eng)\n",
    "french.build_vocab(train_data.fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1624026819079,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "JzMsgXUjzSSC",
    "outputId": "d2442e83-c0a2-4bdd-f2bb-f2dd605fa748"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(french.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 777,
     "status": "ok",
     "timestamp": 1624026819853,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "aU_4KH27zqcM",
    "outputId": "597ad68c-1fa3-4824-dba4-d8c6ae49d61d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1624026819854,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "eS2wlhbrBvSQ"
   },
   "outputs": [],
   "source": [
    "train_iterator, test_iterator = BucketIterator.splits((train_data, test_data), batch_size=32, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1624026819854,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "oRTJU9Ue5i6x",
    "outputId": "1b173552-439c-4c36-b867-558dc95350d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Iterator.data of <torchtext.legacy.data.iterator.BucketIterator object at 0x7fd5a2f3f590>>\n"
     ]
    }
   ],
   "source": [
    "print(train_iterator.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EM6MQlbl0MbP"
   },
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624026819854,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "ht_zxB3L0WJG"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, dp):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(dp)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dp)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624026819854,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "tNe3j_G10WL0"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, dp):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(dp)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dp)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
    "        # is 1 here because we are sending in a single word and not a sentence\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
    "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
    "        # just gonna remove the first dim\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        return predictions, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1624026819854,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "MWC1BDVh4_bK"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(french.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "\n",
    "        hidden, cell = self.encoder(source)\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "\n",
    "            # Store next output prediction\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRhKEd9HQjW2"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1624026819854,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "9nAg5GHo9eNo"
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624026819855,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "mwFIb0QT9fZJ"
   },
   "outputs": [],
   "source": [
    "load_model = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size_encoder = len(english.vocab)\n",
    "input_size_decoder = len(french.vocab)\n",
    "output_size = len(french.vocab)\n",
    "encoder_embedding_size = 100\n",
    "decoder_embedding_size = 100\n",
    "hidden_size = 1024  # Needs to be the same for both RNN's\n",
    "num_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 2073,
     "status": "ok",
     "timestamp": 1624026821924,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "9iEST25m9fgY"
   },
   "outputs": [],
   "source": [
    "# Tensorboard to get nice loss plot\n",
    "writer = SummaryWriter(f\"runs/loss_plot\")\n",
    "step = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1624026821924,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "WV-OQOfE-cIW"
   },
   "outputs": [],
   "source": [
    "train_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.eng),\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 6619,
     "status": "ok",
     "timestamp": 1624026828541,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "Fjyyjlj9-2dD"
   },
   "outputs": [],
   "source": [
    "encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout).to(device)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout).to(device)\n",
    "\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1624026828542,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "l_6_pCvtRJ__"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = french.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1624026828542,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "G3ETZiX6RYDv"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"MT_Seq2Seq.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1624039057150,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "1eQCbk3h02Jn"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, english, french, device, max_length=50):\n",
    "    # print(sentence)\n",
    "\n",
    "\n",
    "    spacy_eng = spacy.load(\"en\")\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    if type(sentence) == str:\n",
    "        tokens = [token.text.lower() for token in spacy_eng(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, english.init_token)\n",
    "    tokens.append(english.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [english.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(sentence_tensor)\n",
    "\n",
    "    outputs = [french.vocab.stoi[\"<sos>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(previous_word, hidden, cell)\n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if output.argmax(1).item() == french.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [french.vocab.itos[idx] for idx in outputs]\n",
    "    translated_sentence = translated_sentence[1:]\n",
    "    translated_sentence = translated_sentence[:-1]\n",
    "\n",
    "    return ' '.join(ix for ix in translated_sentence)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1624026828543,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "iWb9S-kH1Ojs"
   },
   "outputs": [],
   "source": [
    "Original_english_sentence = test.iloc[1]['eng']\n",
    "Original_French_word = test.iloc[1]['fr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9218484,
     "status": "ok",
     "timestamp": 1624036047004,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "XsFe4VyeRcN4",
    "outputId": "6f502bbd-2858-492e-d316-8aa5ffe8ed8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 50]\n",
      "=> Saving checkpoint\n",
      "Original English example sentence: \n",
      " china is never freezing during april  and it is sometimes wet in may \n",
      "original French translated example sentence: \n",
      " chine est jamais le gel en avril  et il est parfois humide en mai \n",
      "Trained French  translated example sentence: \n",
      " lépicerie étatsunis mangues mangues cet août mangues sec sec sec beau sec trouvé beau sec beau sec sec beau sec trouvé beau sec beau sec sec beau sec trouvé beau sec beau sec sec beau sec trouvé beau sec beau sec sec beau sec trouvé beau sec beau sec sec\n",
      "[Epoch 1 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 2 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 3 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 4 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 5 / 50]\n",
      "=> Saving checkpoint\n",
      "Original English example sentence: \n",
      " china is never freezing during april  and it is sometimes wet in may \n",
      "original French translated example sentence: \n",
      " chine est jamais le gel en avril  et il est parfois humide en mai \n",
      "Trained French  translated example sentence: \n",
      " chine est jamais le gel en avril   et il est parfois humide en mai <eos>\n",
      "[Epoch 6 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 7 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 8 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 9 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 10 / 50]\n",
      "=> Saving checkpoint\n",
      "Original English example sentence: \n",
      " china is never freezing during april  and it is sometimes wet in may \n",
      "original French translated example sentence: \n",
      " chine est jamais le gel en avril  et il est parfois humide en mai \n",
      "Trained French  translated example sentence: \n",
      " chine est jamais le gel en avril   et il est parfois humide en mai <eos>\n",
      "[Epoch 11 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 12 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 13 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 14 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 15 / 50]\n",
      "=> Saving checkpoint\n",
      "Original English example sentence: \n",
      " china is never freezing during april  and it is sometimes wet in may \n",
      "original French translated example sentence: \n",
      " chine est jamais le gel en avril  et il est parfois humide en mai \n",
      "Trained French  translated example sentence: \n",
      " chine est jamais le gel en avril   et il est parfois humide en mai <eos>\n",
      "[Epoch 16 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 17 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 18 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 19 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 20 / 50]\n",
      "=> Saving checkpoint\n",
      "Original English example sentence: \n",
      " china is never freezing during april  and it is sometimes wet in may \n",
      "original French translated example sentence: \n",
      " chine est jamais le gel en avril  et il est parfois humide en mai \n",
      "Trained French  translated example sentence: \n",
      " chine est jamais le gel en avril   et il est parfois humide en mai <eos>\n",
      "[Epoch 21 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 22 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 23 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 24 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 25 / 50]\n",
      "=> Saving checkpoint\n",
      "Original English example sentence: \n",
      " china is never freezing during april  and it is sometimes wet in may \n",
      "original French translated example sentence: \n",
      " chine est jamais le gel en avril  et il est parfois humide en mai \n",
      "Trained French  translated example sentence: \n",
      " chine est jamais le gel en avril   et il est parfois humide en mai <eos>\n",
      "[Epoch 26 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 27 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 28 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 29 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 30 / 50]\n",
      "=> Saving checkpoint\n",
      "Original English example sentence: \n",
      " china is never freezing during april  and it is sometimes wet in may \n",
      "original French translated example sentence: \n",
      " chine est jamais le gel en avril  et il est parfois humide en mai \n",
      "Trained French  translated example sentence: \n",
      " chine est jamais le gel en avril   et il est parfois humide en mai <eos>\n",
      "[Epoch 31 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 32 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 33 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 34 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 35 / 50]\n",
      "=> Saving checkpoint\n",
      "Original English example sentence: \n",
      " china is never freezing during april  and it is sometimes wet in may \n",
      "original French translated example sentence: \n",
      " chine est jamais le gel en avril  et il est parfois humide en mai \n",
      "Trained French  translated example sentence: \n",
      " chine est jamais le gel en avril   et il est parfois humide en mai <eos>\n",
      "[Epoch 36 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 37 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 38 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 39 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 40 / 50]\n",
      "=> Saving checkpoint\n",
      "Original English example sentence: \n",
      " china is never freezing during april  and it is sometimes wet in may \n",
      "original French translated example sentence: \n",
      " chine est jamais le gel en avril  et il est parfois humide en mai \n",
      "Trained French  translated example sentence: \n",
      " chine est jamais le gel en avril   et il est parfois humide en mai <eos>\n",
      "[Epoch 41 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 42 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 43 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 44 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 45 / 50]\n",
      "=> Saving checkpoint\n",
      "Original English example sentence: \n",
      " china is never freezing during april  and it is sometimes wet in may \n",
      "original French translated example sentence: \n",
      " chine est jamais le gel en avril  et il est parfois humide en mai \n",
      "Trained French  translated example sentence: \n",
      " chine est jamais le gel en avril   et il est parfois humide en mai <eos>\n",
      "[Epoch 46 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 47 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 48 / 50]\n",
      "=> Saving checkpoint\n",
      "[Epoch 49 / 50]\n",
      "=> Saving checkpoint\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "    save_checkpoint(checkpoint)\n",
    "\n",
    "    if epoch%5 == 0:\n",
    "       model.eval()\n",
    "\n",
    "       translated_sentence = translate_sentence(model, Original_english_sentence, english, french, device, max_length=50)\n",
    "\n",
    "       print(f\"Original English example sentence: \\n {Original_english_sentence}\")\n",
    "       print(f\"original French translated example sentence: \\n {Original_French_word}\")\n",
    "       print(f\"Trained French  translated example sentence: \\n {translated_sentence}\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = batch.eng.to(device)\n",
    "        target = batch.fr.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target)\n",
    "\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Plot to tensorboard\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsmtN_KAZkZW"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1624036047006,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "MvYScm_Zby6K",
    "outputId": "b2d98a3b-bf16-4117-cd96-9f27594c7c3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "load_checkpoint(torch.load(\"MT_Seq2Seq.pth.tar\"), model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1624039083538,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "TPyGEgMwZzUD"
   },
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "def bleu(data, model, english, french, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "\n",
    "    for example in data:\n",
    "        src = vars(example)['eng']\n",
    "        trg = vars(example)[\"fr\"]\n",
    "\n",
    "        prediction = translate_sentence(model, src, english, french, device)\n",
    "        \n",
    "\n",
    "        targets.append([trg])\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    return bleu_score(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 953,
     "status": "ok",
     "timestamp": 1624039107267,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "-JUFK_nwvx_7",
    "outputId": "0436ba10-7477-4b07-edaa-22849e1d2a99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original English example sentence: \n",
      " france is never beautiful during august  but it is never nice in summer \n",
      "original French translated example sentence: \n",
      " la france est jamais belle au mois d août  mais il est jamais agréable en été \n",
      "Trained French  translated example sentence: \n",
      " la france est jamais belle au mois d août   mais il est jamais agréable en été\n"
     ]
    }
   ],
   "source": [
    "Original_english_sentence = test.iloc[3]['eng']\n",
    "Original_French_word = test.iloc[3]['fr']\n",
    "model.eval()\n",
    "\n",
    "translated_sentence = translate_sentence(model, Original_english_sentence, english, french, device, max_length=50)\n",
    "\n",
    "print(f\"Original English example sentence: \\n {Original_english_sentence}\")\n",
    "print(f\"original French translated example sentence: \\n {Original_French_word}\")\n",
    "print(f\"Trained French  translated example sentence: \\n {translated_sentence}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNJdFC0e0cGawpyYX+nw3EU",
   "collapsed_sections": [],
   "name": "MT_E2F_Seq2Seq_Pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
