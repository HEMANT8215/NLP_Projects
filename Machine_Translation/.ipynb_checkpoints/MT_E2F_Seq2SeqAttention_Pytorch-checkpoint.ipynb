{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PWNruoSYrW8"
   },
   "source": [
    "## *Machine Translation English2French Seq2SeqAttention Pytorch*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzwmYrMJItPu"
   },
   "source": [
    "# Import libraries and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19508,
     "status": "ok",
     "timestamp": 1624027017086,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "HrNftJoVIvIy",
    "outputId": "94cf40d5-f917-4c61-bdb9-c8b8416fa79b"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#import os\n",
    "#os.chdir(\"/content/drive/MyDrive/DATA/Machine_Translation_Dataset/MT_E2F_Seq2SeqAttention_Pytorch\")\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2377,
     "status": "ok",
     "timestamp": 1624027019449,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "7oTKHiL7I_sp",
    "outputId": "51440a6d-6462-4ff4-f2a1-3a1bd676a11d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.10.0-cp39-cp39-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torchtext) (1.19.5)\n",
      "Collecting torch\n",
      "  Downloading torch-1.9.0-cp39-none-macosx_11_0_arm64.whl (41.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 41.5 MB 21.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torchtext) (4.61.2)\n",
      "Requirement already satisfied: requests in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torchtext) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests->torchtext) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests->torchtext) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests->torchtext) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests->torchtext) (1.26.6)\n",
      "Requirement already satisfied: typing-extensions in /Users/hemant./miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torch->torchtext) (3.7.4.3)\n",
      "Installing collected packages: torch, torchtext\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4751,
     "status": "ok",
     "timestamp": 1624027024199,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "FgibQAewI_zH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.legacy.data  import Field, BucketIterator, TabularDataset\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3554,
     "status": "ok",
     "timestamp": 1624027027734,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "NMGg6TCKKI-y",
    "outputId": "585783c9-81fe-4f7c-8c23-312d66f18df4"
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "df_english = pd.read_csv('small_vocab_en.csv', sep = '/t', names = ['english'])\n",
    "df_french = pd.read_csv('small_vocab_fr.csv', sep = '/t', names = ['french'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1624027027734,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "oYu0piT3KJB3",
    "outputId": "dcec8900-c711-4b1f-a690-808bb1a09faa"
   },
   "outputs": [],
   "source": [
    "df_english.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1624027027735,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "1FEggqIaO5Ml",
    "outputId": "a9c20d8c-e3dd-44c3-e5d5-c5f55c7aa6e4"
   },
   "outputs": [],
   "source": [
    "df_french.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1624027027735,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "jwhIjtipO8On"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_english, df_french], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1624027027735,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "Onk61NQ6O_HH",
    "outputId": "ff28d337-ac34-4c08-e000-ee4d1dd77d4b"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1624027027735,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "FC7ixXUFPCLo",
    "outputId": "155c5540-8451-4b4b-f2ec-ac7f7905126e"
   },
   "outputs": [],
   "source": [
    "print(\"Total English Records = {}\".format(len(df['english'])))\n",
    "print(\"Total French Records = {}\".format(len(df['french'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrUo7apPPD5G"
   },
   "source": [
    "# Text Cleaning & Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1472,
     "status": "ok",
     "timestamp": 1624027029186,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "5AfNXipSy2E-",
    "outputId": "e69134df-2d42-44de-93cc-56af85720365"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "#from nltk.corpus import stopwords\n",
    "#stopwords_english = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624027029187,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "JA0mTGOey2IE"
   },
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    '''\n",
    "    Input: \n",
    "        text: a string containing a text\n",
    "    Output:\n",
    "        text_clean: a list of words containing the processed text\n",
    "    \n",
    "    '''\n",
    "    # remove number \n",
    "    text = re.sub('[0-9]', '', text)\n",
    "    # remove stock market tickers like $GE\n",
    "    text = re.sub(r'\\$\\w*', '', text)\n",
    "    # remove old style text \"RT\"\n",
    "    text = re.sub(r'^RT[\\s]+', '', text)\n",
    "    # remove hyperlinks\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    # remove the dates like Mar 30 2013\n",
    "    text = re.sub('(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s\\d{2}\\s\\d{4}', ' ', text)\n",
    "    text = re.sub(r\"[/(){}\\[\\]\\|,;.:\\?\\-\\'\\\"$^]\", '', text)\n",
    " \n",
    "    #text = \" \".join(word for word in text.split() if word not in stopwords_english)\n",
    "        \n",
    "\n",
    "    return  text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2663,
     "status": "ok",
     "timestamp": 1624027031847,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "F68ctG8xUqWW"
   },
   "outputs": [],
   "source": [
    "df['eng'] = df['english'].apply(str).apply(process_text)\n",
    "df['fr'] = df['french'].apply(str).apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1624027031847,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "2JrRf181Uw_I"
   },
   "outputs": [],
   "source": [
    "df = df.drop(['english','french'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1624027031848,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "B8B0Rny6QJ_P",
    "outputId": "ccb4c62a-5a19-4322-99e8-f28ae29aa12e"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10089,
     "status": "ok",
     "timestamp": 1624027041917,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "bAUt-7tgSbkb",
    "outputId": "cabb19e5-3c68-4127-b53d-f3e893dafbf0"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download fr\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7535,
     "status": "ok",
     "timestamp": 1624027049444,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "_BaoXc6hBugN"
   },
   "outputs": [],
   "source": [
    "spacy_eng = spacy.load(\"en\")\n",
    "spacy_fr = spacy.load(\"fr\")\n",
    "\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "\n",
    "def tokenize_fr(text):\n",
    "    return [tok.text for tok in spacy_fr.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1624027049444,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "hcbp02c5BvGe"
   },
   "outputs": [],
   "source": [
    "french = Field(tokenize=tokenize_fr, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "english = Field(tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "fields = {(\"eng\", english), (\"fr\", french)}\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1624027049444,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "5m3XfntbUGBn"
   },
   "outputs": [],
   "source": [
    "# create train and test set\n",
    "train, test = train_test_split(df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11579,
     "status": "ok",
     "timestamp": 1624027061015,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "2jYVW2ALBvMm"
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "train_data, test_data = TabularDataset.splits( path=\"\", train=\"train.csv\", test=\"test.csv\", format=\"csv\", fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 888,
     "status": "ok",
     "timestamp": 1624027061895,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "Zxdh8qukBvPV"
   },
   "outputs": [],
   "source": [
    "english.build_vocab(train_data.eng)\n",
    "french.build_vocab(train_data.fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1624027061895,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "JzMsgXUjzSSC",
    "outputId": "f6ccf1ab-eaf7-4af0-848b-1e7a9729f296"
   },
   "outputs": [],
   "source": [
    "len(french.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1624027061896,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "aU_4KH27zqcM",
    "outputId": "c485a64a-cf92-49a6-e802-43f39bc9d6df"
   },
   "outputs": [],
   "source": [
    "len(english.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1624027061896,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "eS2wlhbrBvSQ"
   },
   "outputs": [],
   "source": [
    "train_iterator, test_iterator = BucketIterator.splits((train_data, test_data), batch_size=32, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EM6MQlbl0MbP"
   },
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1624027061896,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "7mcUi2sC0t8e"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True)\n",
    "\n",
    "        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        encoder_states, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        # Use forward, backward cells and hidden through a linear layer\n",
    "        # so that it can be input to the decoder which is not bidirectional\n",
    "        # Also using index slicing ([idx:idx+1]) to keep the dimension\n",
    "        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "\n",
    "        return encoder_states, hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(hidden_size * 2 + embedding_size, hidden_size, num_layers)\n",
    "\n",
    "        self.energy = nn.Linear(hidden_size * 3, 1)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "        # x: (1, N) where N is the batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        sequence_length = encoder_states.shape[0]\n",
    "        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
    "        # h_reshaped: (seq_length, N, hidden_size*2)\n",
    "\n",
    "        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
    "        # energy: (seq_length, N, 1)\n",
    "\n",
    "        attention = self.softmax(energy)\n",
    "        # attention: (seq_length, N, 1)\n",
    "\n",
    "        # attention: (seq_length, N, 1), snk\n",
    "        # encoder_states: (seq_length, N, hidden_size*2), snl\n",
    "        # we want context_vector: (1, N, hidden_size*2), i.e knl\n",
    "        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_states)\n",
    "\n",
    "        rnn_input = torch.cat((context_vector, embedding), dim=2)\n",
    "        # rnn_input: (1, N, hidden_size*2 + embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs).squeeze(0)\n",
    "        # predictions: (N, hidden_size)\n",
    "\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(french.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "        encoder_states, hidden, cell = self.encoder(source)\n",
    "\n",
    "        # First input will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # At every time step use encoder_states and update hidden, cell\n",
    "            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
    "\n",
    "            # Store prediction for current time step\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRhKEd9HQjW2"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1624027061897,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "iCApPJiWvv-R"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"MT_Seq2SeqAttention.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12869339,
     "status": "ok",
     "timestamp": 1624040004696,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "yDblZEeQqFva",
    "outputId": "ed5427f5-54a9-4d0b-ef3f-c25235af801a"
   },
   "outputs": [],
   "source": [
    "### We're ready to define everything we need for training our Seq2Seq model ###\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 50\n",
    "learning_rate = 3e-4\n",
    "batch_size = 32\n",
    "\n",
    "# Model hyperparameters\n",
    "input_size_encoder = len(english.vocab)\n",
    "input_size_decoder = len(french.vocab)\n",
    "output_size = len(french.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 1\n",
    "enc_dropout = 0.0\n",
    "dec_dropout = 0.0\n",
    "\n",
    "# Tensorboard to get nice loss plot\n",
    "writer = SummaryWriter(f\"runs/loss_plot\")\n",
    "step = 0\n",
    "\n",
    "train_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.eng),\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout).to(device)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_layers,\n",
    "    dec_dropout,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "pad_idx = french.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "\n",
    "def translate_sentence(model, sentence, french, english, device, max_length=50):\n",
    "    spacy_eng = spacy.load(\"en\")\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    if type(sentence) == str:\n",
    "        tokens = [token.text.lower() for token in spacy_eng(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, english.init_token)\n",
    "    tokens.append(english.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [english.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        outputs_encoder, hiddens, cells = model.encoder(sentence_tensor)\n",
    "\n",
    "    outputs = [french.vocab.stoi[\"<sos>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hiddens, cells = model.decoder(\n",
    "                previous_word, outputs_encoder, hiddens, cells\n",
    "            )\n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if output.argmax(1).item() == french.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [french.vocab.itos[idx] for idx in outputs]\n",
    "\n",
    "    return ' '.join(ix for ix in translated_sentence[1:])\n",
    "\n",
    "Original_english_sentence = test.iloc[1]['eng']\n",
    "Original_French_word = test.iloc[1]['fr']\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "    save_checkpoint(checkpoint)\n",
    "\n",
    "    if epoch%5 == 0:\n",
    "       model.eval()\n",
    "\n",
    "       translated_sentence = translate_sentence(model, Original_english_sentence, french, english, device, max_length=50)\n",
    "\n",
    "       print(f\"Original English example sentence: \\n {Original_english_sentence}\")\n",
    "       print(f\"original French translated example sentence: \\n {Original_French_word}\")\n",
    "       print(f\"Trained French  translated example sentence: \\n {translated_sentence}\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = batch.eng.to(device)\n",
    "        target = batch.fr.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target)\n",
    "\n",
    "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have output_words * batch_size that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin. While we're at it\n",
    "        # Let's also remove the start token while we're at it\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Plot to tensorboard\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsmtN_KAZkZW"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 680,
     "status": "ok",
     "timestamp": 1624040005366,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "MvYScm_Zby6K",
    "outputId": "ec33d510-4cd2-46f7-a638-9a24253dcdfd"
   },
   "outputs": [],
   "source": [
    "load_checkpoint(torch.load(\"MT_Seq2SeqAttention.pth.tar\"), model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 430,
     "status": "ok",
     "timestamp": 1624040353970,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "OqfZgNKH0hxw"
   },
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "def bleu(data, model, english, french, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "\n",
    "    for example in data:\n",
    "        src = vars(example)['eng']\n",
    "        trg = vars(example)[\"fr\"]\n",
    "\n",
    "        prediction = translate_sentence(model, src, french, english, device)\n",
    "        \n",
    "\n",
    "        targets.append([trg])\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    return bleu_score(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1624040005368,
     "user": {
      "displayName": "hemant sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09562798786707226656"
     },
     "user_tz": -330
    },
    "id": "Yh1tDmV90k9Q",
    "outputId": "1ccdd659-d25c-40b3-e0ba-ee7f6aab7046"
   },
   "outputs": [],
   "source": [
    "Original_english_sentence = test.iloc[3]['eng']\n",
    "Original_French_word = test.iloc[3]['fr']\n",
    "model.eval()\n",
    "\n",
    "translated_sentence = translate_sentence(model, Original_english_sentence, french, english, device, max_length=50)\n",
    "\n",
    "print(f\"Original English example sentence: \\n {Original_english_sentence}\")\n",
    "print(f\"original French translated example sentence: \\n {Original_French_word}\")\n",
    "print(f\"Trained French  translated example sentence: \\n {translated_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ko32547WWrWI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNXE1n0IxvDyjJACNWx6Eke",
   "collapsed_sections": [],
   "name": "MT_E2F_Seq2SeqAttention_Pytorch.ipynb",
   "provenance": [
    {
     "file_id": "16l8WSq6GVK2Ksp2Nr7QsjHtuY9n9xG8U",
     "timestamp": 1623825651074
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
