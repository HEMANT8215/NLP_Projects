{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chatbot.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPgOmewOVsX1Q1VbtX4L8dq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1Jdq0vU8o1o","executionInfo":{"status":"ok","timestamp":1625150890200,"user_tz":-330,"elapsed":52314,"user":{"displayName":"hemant sharma","photoUrl":"","userId":"09562798786707226656"}},"outputId":"b6b5e26e-bce7-40be-f583-04f46654271c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"/content/drive/MyDrive/DATA/Chatbot\")\n","!ls"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","data.pth  Intent.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqL-BO3R92fM","executionInfo":{"status":"ok","timestamp":1625150905407,"user_tz":-330,"elapsed":5591,"user":{"displayName":"hemant sharma","photoUrl":"","userId":"09562798786707226656"}},"outputId":"6fd40c74-15bd-46ef-a7ff-363f5db6be8a"},"source":["import pandas as pd\n","import random\n","import json\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import tensorflow as tf\n","import nltk\n","nltk.download('punkt')\n","from nltk.stem.porter import PorterStemmer\n","stemmer = PorterStemmer()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qPZc_X129-V9","executionInfo":{"status":"ok","timestamp":1625150906032,"user_tz":-330,"elapsed":640,"user":{"displayName":"hemant sharma","photoUrl":"","userId":"09562798786707226656"}}},"source":["def tokenize(sentence):\n","    \"\"\"\n","    split sentence into array of words/tokens\n","    a token can be a word or punctuation character, or number\n","    \"\"\"\n","    return nltk.word_tokenize(sentence)\n","\n","\n","def stem(word):\n","    \"\"\"\n","    stemming = find the root form of the word\n","    examples:\n","    words = [\"organize\", \"organizes\", \"organizing\"]\n","    words = [stem(w) for w in words]\n","    -> [\"organ\", \"organ\", \"organ\"]\n","    \"\"\"\n","    return stemmer.stem(word.lower())\n","\n","\n","def bag_of_words(tokenized_sentence, words):\n","    \"\"\"\n","    return bag of words array:\n","    1 for each known word that exists in the sentence, 0 otherwise\n","    example:\n","    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n","    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n","    bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]\n","    \"\"\"\n","    # stem each word\n","    sentence_words = [stem(word) for word in tokenized_sentence]\n","    # initialize bag with 0 for each word\n","    bag = np.zeros(len(words), dtype=np.float32)\n","    for idx, w in enumerate(words):\n","        if w in sentence_words: \n","            bag[idx] = 1\n","\n","    return bag"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UCkx4i6O-D_o","executionInfo":{"status":"ok","timestamp":1625150906033,"user_tz":-330,"elapsed":7,"user":{"displayName":"hemant sharma","photoUrl":"","userId":"09562798786707226656"}},"outputId":"5a85c392-acfc-4c9c-83c1-1ca33ef11444"},"source":["with open('Intent.json', 'r') as f:\n","    intents = json.load(f)\n","\n","all_words = []\n","tags = []\n","xy = []\n","# loop through each sentence in our intents patterns\n","for intent in intents['intents']:\n","    tag = intent['intent']\n","    # add to tag list\n","    tags.append(tag)\n","    for pattern in intent['text']:\n","        # tokenize each word in the sentence\n","        w = tokenize(pattern)\n","        # add to our words list\n","        all_words.extend(w)\n","        # add to xy pair\n","        xy.append((w, tag))\n","\n","# stem and lower each word\n","ignore_words = ['?', '.', '!']\n","all_words = [stem(w) for w in all_words if w not in ignore_words]\n","# remove duplicates and sort\n","all_words = sorted(set(all_words))\n","tags = sorted(set(tags))\n","\n","print(len(xy), \"patterns\")\n","print(len(tags), \"tags:\", tags)\n","print(len(all_words), \"unique stemmed words:\", all_words)\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["143 patterns\n","22 tags: ['Clever', 'CourtesyGoodBye', 'CourtesyGreeting', 'CourtesyGreetingResponse', 'CurrentHumanQuery', 'GoodBye', 'Gossip', 'Greeting', 'GreetingResponse', 'Jokes', 'NameQuery', 'NotTalking2U', 'PodBayDoor', 'PodBayDoorResponse', 'RealNameQuery', 'SelfAware', 'Shutup', 'Swearing', 'Thanks', 'TimeQuery', 'UnderstandQuery', 'WhoAmI']\n","114 unique stemmed words: [\"'s\", ',', 'a', 'about', 'adam', 'adio', 'am', 'ani', 'anyon', 'are', 'awar', 'bay', 'be', 'bella', 'bore', 'by', 'bye', 'call', 'camera', 'can', 'cheer', 'clever', 'commun', 'comprendo', 'consciou', 'could', 'do', 'door', 'enough', 'for', 'friend', 'fuck', 'geniou', 'get', 'girl', 'give', 'good', 'goodby', 'gossip', 'got', 'great', 'have', 'hear', 'hello', 'help', 'hi', 'hola', 'hope', 'how', 'hya', 'i', 'identifi', 'in', 'intellig', 'is', 'it', 'joke', 'know', 'later', 'laugh', 'make', 'me', 'mean', 'meant', 'more', 'my', \"n't\", 'name', 'need', 'not', 'off', 'ok', 'open', 'pleas', 'pod', 'prove', 'quiet', 'real', 'say', 'see', 'self', 'self-awar', 'shhh', 'shit', 'shut', 'some', 'speak', 'stop', 'sure', 'talk', 'tell', 'thank', 'that', 'the', 'there', 'thi', 'think', 'time', 'to', 'twat', 'understand', 'up', 'user', 'veri', 'wa', 'want', 'well', 'what', 'whi', 'who', 'will', 'with', 'you', 'your']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3g0iRx57-zS4","executionInfo":{"status":"ok","timestamp":1625150906033,"user_tz":-330,"elapsed":6,"user":{"displayName":"hemant sharma","photoUrl":"","userId":"09562798786707226656"}}},"source":["# create training data\n","X_train = []\n","y_train = []\n","for (pattern_sentence, tag) in xy:\n","    # X: bag of words for each pattern_sentence\n","    bag = bag_of_words(pattern_sentence, all_words)\n","    X_train.append(bag)\n","    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n","    label = tags.index(tag)\n","    y_train.append(label)\n","\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WEKhyTZJoPRR","executionInfo":{"status":"ok","timestamp":1625150906033,"user_tz":-330,"elapsed":5,"user":{"displayName":"hemant sharma","photoUrl":"","userId":"09562798786707226656"}},"outputId":"0d4dd682-1bb7-47e1-b85b-a0c8a8b7d0df"},"source":["X_train.shape"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(143, 114)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"9_h16-BhoNL8","executionInfo":{"status":"ok","timestamp":1625150906516,"user_tz":-330,"elapsed":9,"user":{"displayName":"hemant sharma","photoUrl":"","userId":"09562798786707226656"}}},"source":["class ChatDataset(Dataset):\n","\n","    def __init__(self):\n","        self.n_samples = len(X_train)\n","        self.x_data = X_train\n","        self.y_data = y_train\n","\n","    # support indexing such that dataset[i] can be used to get i-th sample\n","    def __getitem__(self, index):\n","        return self.x_data[index], self.y_data[index]\n","\n","    # we can call len(dataset) to return the size\n","    def __len__(self):\n","        return self.n_samples"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"GUsFse07_Hub","executionInfo":{"status":"ok","timestamp":1625150906517,"user_tz":-330,"elapsed":10,"user":{"displayName":"hemant sharma","photoUrl":"","userId":"09562798786707226656"}}},"source":["class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNet, self).__init__()\n","        self.l1 = nn.Linear(input_size, hidden_size) \n","        self.l2 = nn.Linear(hidden_size, hidden_size) \n","        self.l3 = nn.Linear(hidden_size, num_classes)\n","        self.relu = nn.ReLU()\n","    \n","    def forward(self, x):\n","        out = self.l1(x)\n","        out = self.relu(out)\n","        out = self.l2(out)\n","        out = self.relu(out)\n","        out = self.l3(out)\n","        # no activation and no softmax at the end\n","        return out"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wRaeOVUu-8cQ","executionInfo":{"status":"ok","timestamp":1625150980483,"user_tz":-330,"elapsed":413,"user":{"displayName":"hemant sharma","photoUrl":"","userId":"09562798786707226656"}},"outputId":"1c5fbe3b-26f9-4caa-d00f-2eb4913a341c"},"source":["# Hyper-parameters \n","num_epochs = 500\n","batch_size = 8\n","learning_rate = 0.001\n","input_size = len(X_train[0])\n","hidden_size = 8\n","num_layers = 6\n","output_size = len(tags)\n","\n","print(input_size, num_classes)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","dataset = ChatDataset()\n","train_loader = DataLoader(dataset=dataset,\n","                          batch_size=batch_size,\n","                          shuffle=True,\n","                          num_workers=0)\n","\n","model = NeuralNet(input_size, hidden_size, output_size).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["114 22\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kP9XOgajoQyL","executionInfo":{"status":"ok","timestamp":1625150980877,"user_tz":-330,"elapsed":11,"user":{"displayName":"hemant sharma","photoUrl":"","userId":"09562798786707226656"}},"outputId":"1bfc7c73-590c-42b7-e176-f104cae874d9"},"source":["print(model)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["NeuralNet(\n","  (l1): Linear(in_features=114, out_features=8, bias=True)\n","  (l2): Linear(in_features=8, out_features=8, bias=True)\n","  (l3): Linear(in_features=8, out_features=22, bias=True)\n","  (relu): ReLU()\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALtCLDsp_FUE","executionInfo":{"status":"ok","timestamp":1625151000649,"user_tz":-330,"elapsed":11736,"user":{"displayName":"hemant sharma","photoUrl":"","userId":"09562798786707226656"}},"outputId":"3ed1c478-9c48-4cff-b453-86fed12ce228"},"source":["# Train the model\n","for epoch in range(num_epochs):\n","    for (words, labels) in train_loader:\n","        words = words.to(device)\n","        labels = labels.to(dtype=torch.long).to(device)\n","        \n","        # Forward pass\n","        outputs = model(words)\n","        # if y would be one-hot, we must apply\n","        # labels = torch.max(labels, 1)[1]\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","    if (epoch+1) % 100 == 0:\n","        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","\n","print(f'final loss: {loss.item():.4f}')\n","\n","data = {\n","\"model_state\": model.state_dict(),\n","\"input_size\": input_size,\n","\"hidden_size\": hidden_size,\n","\"output_size\": output_size,\n","\"all_words\": all_words,\n","\"tags\": tags\n","}\n","\n","FILE = \"data.pth\"\n","torch.save(data, FILE)\n","\n","print(f'training complete. file saved to {FILE}')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Epoch [100/500], Loss: 0.1737\n","Epoch [200/500], Loss: 0.0088\n","Epoch [300/500], Loss: 0.0104\n","Epoch [400/500], Loss: 0.0004\n","Epoch [500/500], Loss: 0.0002\n","final loss: 0.0002\n","training complete. file saved to data.pth\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I2a6qufV_dkW","executionInfo":{"status":"ok","timestamp":1625151111243,"user_tz":-330,"elapsed":41220,"user":{"displayName":"hemant sharma","photoUrl":"","userId":"09562798786707226656"}},"outputId":"630bbc65-2593-4736-e746-d8c1196e155f"},"source":["FILE = \"data.pth\"\n","data = torch.load(FILE)\n","\n","input_size = data[\"input_size\"]\n","hidden_size = data[\"hidden_size\"]\n","output_size = data[\"output_size\"]\n","all_words = data['all_words']\n","tags = data['tags']\n","model_state = data[\"model_state\"]\n","\n","model = NeuralNet(input_size, hidden_size, output_size).to(device)\n","model.load_state_dict(model_state)\n","model.eval()\n","\n","bot_name = \"Sam\"\n","print(\"Let's chat! (type 'quit' to exit)\")\n","while True:\n","    # sentence = \"do you use credit cards?\"\n","    sentence = input(\"You: \")\n","    if sentence == \"quit\":\n","        break\n","\n","    sentence = tokenize(sentence)\n","    X = bag_of_words(sentence, all_words)\n","    X = X.reshape(1, X.shape[0])\n","    X = torch.from_numpy(X).to(device)\n","\n","    output = model(X)\n","    _, predicted = torch.max(output, dim=1)\n","\n","    tag = tags[predicted.item()]\n","\n","    probs = torch.softmax(output, dim=1)\n","    prob = probs[0][predicted.item()]\n","    if prob.item() > 0.75:\n","        for intent in intents['intents']:\n","            if tag == intent[\"intent\"]:\n","                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n","    else:\n","        print(f\"{bot_name}: I do not understand...\")\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Let's chat! (type 'quit' to exit)\n","You: hi \n","Sam: Hi human, please tell me your GeniSys user\n","You: my name is alan\n","Sam: <HUMAN>, what can I do for you?\n","You: tell me a joke\n","Sam: Van Gogh goes into a pub and his mate asks him if he wants a drink. 'No thanks', said Vincent, 'I've got one ear.'\n","You: thank you \n","Sam: My pleasure\n","You: quit\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I7X2pu8amYl4","executionInfo":{"status":"ok","timestamp":1625151066026,"user_tz":-330,"elapsed":13,"user":{"displayName":"hemant sharma","photoUrl":"","userId":"09562798786707226656"}}},"source":[""],"execution_count":16,"outputs":[]}]}